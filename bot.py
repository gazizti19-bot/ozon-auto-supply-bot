#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SellMate | Escanor ‚Äî Ozon FBO Telegram Bot
Version stable-grounded-1.7.7

–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:
- –ö–Ω–æ–ø–∫–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤ "–ö—Ä–∏—Ç–∏—á–Ω–æ" –∏ "50‚Äì80%" —Ç–µ–ø–µ—Ä—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–∞—Å—Å—ã–ª–∫–µ:
  ‚Ä¢ –í daily_notify_job –∫—ç—à LAST_DEFICIT_CACHE –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è.
  ‚Ä¢ –í –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ cb_filter –¥–æ–±–∞–≤–ª–µ–Ω —Ñ–æ–ª–±—ç–∫: –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–µ—Å—á—ë—Ç.
- –í —Å–ø–∏—Å–∫–µ ‚Äúüìã –ó–∞–¥–∞—á–∏‚Äù –∏ –≤ —Å–ø–∏—Å–∫–µ ‚ÄúüìÑ –ó–∞—è–≤–∫–∏‚Äù —è–≤–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã: ¬´–°–∫–ª–∞–¥ –ø–æ—Å—Ç–∞–≤–∫–∏¬ª –∏ ¬´–ö—Ä–æ—Å—Å–¥–æ–∫¬ª.
- –í ‚ÄúüìÑ –ó–∞—è–≤–∫–∏‚Äù –¥–æ–±–∞–≤–ª–µ–Ω —è–≤–Ω—ã–π —Å—Ç–∞—Ç—É—Å: ¬´–°—Ç–∞—Ç—É—Å: ‚úÖ –°–æ–∑–¥–∞–Ω–æ¬ª –¥–ª—è ORDER_DATA_FILLING/CREATED –∏ ¬´–°—Ç–∞—Ç—É—Å: ‚úÖ –ì–æ—Ç–æ–≤–æ¬ª –¥–ª—è DONE.
- build_supplies_last_created –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫—É ¬´–°—Ç–∞—Ç—É—Å: ‚úÖ –°–æ–∑–¥–∞–Ω–æ¬ª –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã.
- –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞—è–≤–∫–∏: –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –∑–∞–¥–∞—á/–∑–∞—è–≤–æ–∫ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º ¬´—Å–æ–∑–¥–∞–Ω–Ω—ã–µ¬ª (–≤–∫–ª—é—á–∞—è ORDER_DATA_FILLING),
  –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –∑–∞—è–≤–∫—É (c –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–µ–π).
- ORDER_DATA_FILLING –∏—Å–∫–ª—é—á—ë–Ω –∏–∑ ¬´üìã –ó–∞–¥–∞—á–∏¬ª (–ø–µ—Ä–µ–Ω–µ—Å—ë–Ω –≤ ¬´üìÑ –ó–∞—è–≤–∫–∏¬ª), –ø–ª—é—Å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ.
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞–¥–∏–π: —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ/—Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–¥–∏–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Ä–∞–Ω—å—à–µ ¬´–û—à–∏–±–∫–∞¬ª,
  —á—Ç–æ–±—ã –≥–æ—Ç–æ–≤—ã–µ –∑–∞—è–≤–∫–∏ –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å –∫–∞–∫ ¬´–û—à–∏–±–∫–∞¬ª.
"""

import os
os.environ["AUTO_BOOK"] = os.getenv("AUTO_BOOK", "0")

from typing import Callable, Dict, Any, Awaitable, Set, Optional, List, Tuple
from aiogram import BaseMiddleware
from aiogram.types import TelegramObject, Message, CallbackQuery

# ===================== ACL MIDDLEWARE =====================
def _parse_ids_env(key: str) -> Set[int]:
    raw = os.getenv(key, "") or ""
    ids: Set[int] = set()
    for part in raw.replace(" ", "").split(","):
        if part.isdigit():
            try:
                ids.add(int(part))
            except Exception:
                pass
    return ids

def _parse_usernames_env(key: str) -> Set[str]:
    raw = os.getenv(key, "") or ""
    names: Set[str] = set()
    for part in raw.split(","):
        part = part.strip()
        if not part:
            continue
        if part.startswith("@"):
            part = part[1:]
        names.add(part.lower())
    return names

class ACLMiddleware(BaseMiddleware):
    def __init__(self,
                 allowed_ids: Set[int],
                 allowed_usernames: Set[str],
                 deny_message: Optional[str] = None) -> None:
        super().__init__()
        self.allowed_ids = allowed_ids or set()
        self.allowed_usernames = {u for u in (allowed_usernames or set()) if u}
        self.deny_message = (deny_message or "").strip() or None

    def _is_allowed(self, user) -> bool:
        try:
            # –ï—Å–ª–∏ —Å–ø–∏—Å–∫–∏ –ø—É—Å—Ç—ã–µ ‚Äî –ø—É—Å–∫–∞–µ–º –≤—Å–µ—Ö
            if (not self.allowed_ids) and (not self.allowed_usernames):
                return True
        except Exception:
            pass
        try:
            # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –∑–∞–ø—É—Å–∫–∞–ª /start ‚Äî –æ–Ω –≤ KNOWN_USERS
            if 'KNOWN_USERS' in globals() and hasattr(user, 'id'):
                if int(user.id) in globals()['KNOWN_USERS']:
                    return True
        except Exception:
            pass
        try:
            if int(user.id) in self.allowed_ids:
                return True
        except Exception:
            pass
        uname = (getattr(user, "username", None) or "").strip()
        if uname:
            if uname.lower().lstrip("@") in self.allowed_usernames:
                return True
        return False

    async def __call__(
        self,
        handler: Callable[[TelegramObject, Dict[str, Any]], Awaitable[Any]],
        event: TelegramObject,
        data: Dict[str, Any],
    ) -> Any:
        user = data.get("event_from_user")
        if not user:
            return
        if self._is_allowed(user):
            return await handler(event, data)
        if self.deny_message:
            bot = data.get("bot")
            if bot:
                try:
                    if isinstance(event, Message):
                        await bot.send_message(chat_id=user.id, text=self.deny_message)
                    elif isinstance(event, CallbackQuery):
                        await bot.send_message(chat_id=user.id, text=self.deny_message)
                except Exception:
                    pass
        return
# =================== END ACL MIDDLEWARE ===================

import asyncio
import logging
import json
import math
import time
import re
import uuid
import hashlib
import signal
import tempfile
import inspect
from pathlib import Path
from zoneinfo import ZoneInfo
import html
import sys as _sys, os as _os
import datetime  # –≤–∞–∂–Ω–æ –¥–ª—è _human_window

_ROOT_DIR = _os.path.dirname(_os.path.abspath(__file__))
if _ROOT_DIR not in _sys.path:
    _sys.path.insert(0, _ROOT_DIR)

from dotenv import load_dotenv
load_dotenv()

# ===== External modules (supply) =====
try:
    import supply_integration as si
except Exception as _e:
    si = None
    logging.getLogger("ozon-bot").warning("supply_integration not available: %s", _e)

try:
    import supply_watch as sw
except Exception as _e:
    sw = None
    logging.getLogger("ozon-bot").warning("supply_watch module not available: %s", _e)

try:
    from supply_watch import register_supply_scheduler
except Exception:
    def register_supply_scheduler(*args, **kwargs):
        logging.getLogger("ozon-bot").warning("register_supply_scheduler not available.")
        return None

try:
    from supply_watch import purge_tasks, purge_all_tasks
except Exception:
    purge_tasks = None
    purge_all_tasks = None

AUTOBOOK_ENABLED = False
_AUTOBOOK_IMPORT_ERROR: Optional[str] = None
try:
    import flows.autobook_flow as abf
    autobook_router = abf.router
    AUTOBOOK_ENABLED = True
except Exception as e:
    autobook_router = None
    AUTOBOOK_ENABLED = False
    _AUTOBOOK_IMPORT_ERROR = f"{e.__class__.__name__}: {e}"

VERSION = "stable-grounded-1.7.7"

import httpx
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from aiogram import Bot, Dispatcher, F
from aiogram.types import (
    Message, CallbackQuery, ReplyKeyboardMarkup, KeyboardButton,
    InlineKeyboardMarkup, InlineKeyboardButton, FSInputFile
)
from aiogram.filters import Command
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.exceptions import TelegramRetryAfter

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
OZON_CLIENT_ID = os.getenv("OZON_CLIENT_ID", "").strip()
OZON_API_KEY = os.getenv("OZON_API_KEY", "").strip()

DEFAULT_DROPOFF_ID = (os.getenv("OZON_DROP_OFF_ID") or os.getenv("DEFAULT_DROPOFF_ID") or os.getenv("DROP_ID") or "").strip()
DEFAULT_DROPOFF_NAME = (
    os.getenv("OZON_DROP_OFF_NAME")
    or os.getenv("DEFAULT_D–†–û–ü–ûFF_NAME")  # –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –æ–ø–µ—á–∞—Ç–∫–∏ –∫–ª—é—á–∞ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ (–≤–æ–∑–º–æ–∂–Ω—ã –∫–∏—Ä–∏–ª–ª. –±—É–∫–≤—ã)
    or os.getenv("DEFAULT_DROPOFF_NAME")
    or os.getenv("DROP_NAME")
    or os.getenv("DEFAULT_DROP_OFF_NAME")
    or ""
).strip()

TIMEWINDOWS_RAW = os.getenv("TIMEWINDOWS", "09:00-12:00;12:00-15:00;15:00-18:00")
DAYS_ENV = int(os.getenv("DAYS", "3"));  DAYS_ENV = 3 if DAYS_ENV <= 0 else DAYS_ENV
DISABLE_TS_FALLBACK = (os.getenv("DISABLE_TS_FALLBACK") or os.getenv("OZON_TIMESLOT_DISABLE_FALLBACK") or "0") in ("1","true","True","TRUE")

MIN_STOCK = int(os.getenv("MIN_STOCK", "100"))
TARGET_MULTIPLIER = float(os.getenv("TARGET_MULTIPLIER", "2"))
HISTORY_RETENTION_DAYS = int(os.getenv("HISTORY_RETENTION_DAYS", "120"))
HISTORY_LOOKBACK_DAYS = int(os.getenv("HISTORY_LOOKBACK_DAYS", "90"))
MIN_HISTORY_HOURS = float(os.getenv("MIN_HISTORY_HOURS", "6"))
MAX_HISTORY_POINTS = int(os.getenv("MAX_HISTORY_POINTS", "300"))
MAX_HISTORY_SNAPSHOTS = int(os.getenv("MAX_HISTORY_SNAPSHOTS", "5000"))

SNAPSHOT_INTERVAL_MINUTES = int(os.getenv("SNAPSHOT_INTERVAL_MINUTES", "30"))
SNAPSHOT_STALE_MINUTES = int(os.getenv("SNAPSHOT_STALE_MINUTES", "15"))
SNAPSHOT_MIN_REUSE_SECONDS = int(os.getenv("SNAPSHOT_MIN_REUSE_SECONDS", "120"))
HISTORY_PRUNE_EVERY_MINUTES = int(os.getenv("HISTORY_PRUNE_EVERY_MINUTES", "360"))

DAILY_NOTIFY_HOUR = int(os.getenv("DAILY_NOTIFY_HOUR", "9"))
DAILY_NOTIFY_MINUTE = int(os.getenv("DAILY_NOTIFY_MINUTE", "0"))
TZ_NAME = os.getenv("TZ", "UTC")

API_TIMEOUT_SECONDS = int(os.getenv("API_TIMEOUT_SECONDS", "15"))
HEALTH_WARN_LATENCY_MS = int(os.getenv("HEALTH_WARN_LATENCY_MS", "4000"))
SAVE_BUFFER_FLUSH_SECONDS = int(os.getenv("SAVE_BUFFER_FLUSH_SECONDS", "30"))

DEFAULT_VIEW_MODE = "FULL"

LLM_PROVIDER = os.getenv("LLM_PROVIDER", "").lower().strip()

def _clean(v: str) -> str:
    return (v or "").strip().strip('"').strip("'")

# ==== GigaChat config ====
GIGACHAT_CLIENT_ID = _clean(os.getenv("GIGACHAT_CLIENT_ID", ""))
GIGACHAT_CLIENT_SECRET = _clean(os.getenv("GIGACHAT_CLIENT_SECRET", ""))
GIGACHAT_SCOPE = _clean(os.getenv("GIGACHAT_SCOPE", "GIGACHAT_API_B2B"))
GIGACHAT_TOKEN_URL = _clean(os.getenv("GIGACHAT_TOKEN_URL", "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"))
GIGACHAT_API_URL = _clean(os.getenv("GIGACHAT_API_URL", "https://gigachat.devices.sberbank.ru/api/v1/chat/completions"))
GIGACHAT_MODEL = _clean(os.getenv("GIGACHAT_MODEL", "GigaChat"))
GIGACHAT_TEMPERATURE = float(os.getenv("GIGACHAT_TEMPERATURE", "0.3"))
GIGACHAT_MAX_TOKENS = int(os.getenv("GIGACHAT_MAX_TOKENS", "800"))
GIGACHAT_TIMEOUT_SECONDS = int(os.getenv("GIGACHAT_TIMEOUT_SECONDS", "40"))
GIGACHAT_VERIFY_SSL = os.getenv("GIGACHAT_VERIFY_SSL", "1") != "0"
GIGACHAT_SSL_MODE = _clean(os.getenv("GIGACHAT_SSL_MODE", "auto")).lower()
GIGACHAT_CA_CERT = _clean(os.getenv("GIGACHAT_CA_CERT", "/app/ca/gigachat_ca.pem"))
GIGACHAT_TOKEN_CACHE_ENV = _clean(os.getenv("GIGACHAT_TOKEN_CACHE", "keys/gigachat_token_cache.json"))

LLM_FORCE_FACT_MODE = os.getenv("LLM_FORCE_FACT_MODE", "1") == "1"
AI_MIN_INTERVAL_SECONDS = int(os.getenv("AI_MIN_INTERVAL_SECONDS", "5"))
LLM_TOP_DEFICITS = int(os.getenv("LLM_TOP_DEFICITS", "20"))
LLM_TOP_WAREHOUSES = int(os.getenv("LLM_TOP_WAREHOUSES", "8"))
LLM_TOP_CLUSTERS = int(os.getenv("LLM_TOP_CLUSTERS", "8"))
LLM_MAX_CONTEXT_SKU = int(os.getenv("LLM_MAX_CONTEXT_SKU", "10"))
LLM_MAX_CONTEXT_WAREHOUSE = int(os.getenv("LLM_MAX_CONTEXT_WAREHOUSE", "6"))
LLM_INVENTORY_SAMPLE_SKU = int(os.getenv("LLM_INVENTORY_SAMPLE_SKU", "50"))
LLM_FULL_DETAIL_SKU = int(os.getenv("LLM_FULL_DETAIL_SKU", "25"))
LLM_FULL_DETAIL_WAREHOUSES = int(os.getenv("LLM_FULL_DETAIL_WAREHOUSES", "6"))
LLM_FACT_SOFT_LIMIT_CHARS = int(os.getenv("LLM_FACT_SOFT_LIMIT_CHARS", "18000"))
LLM_ENABLE_ANSWER_CACHE = os.getenv("LLM_ENABLE_ANSWER_CACHE", "1") == "1"
LLM_STYLE_ENABLED = os.getenv("LLM_STYLE_ENABLED", "1") == "1"
LLM_GENERAL_TEMPERATURE = float(os.getenv("LLM_GENERAL_TEMPERATURE", "0.7"))
GENERAL_HISTORY_MAX = int(os.getenv("GENERAL_HISTORY_MAX", "12"))
DEFAULT_CHAT_MODE = _clean(os.getenv("DEFAULT_CHAT_MODE", "fact")).lower()

DIAG_TOP_DEFICITS = int(os.getenv("DIAG_TOP_DEFICITS", "8"))
DIAG_TOP_WAREHOUSES = int(os.getenv("DIAG_TOP_WAREHOUSES", "6"))
DIAG_TOP_CLUSTERS = int(os.getenv("DIAG_TOP_CLUSTERS", "6"))

WAREHOUSE_CLUSTERS_ENV = os.getenv("WAREHOUSE_CLUSTERS", "").strip()

STOCK_PAGE_SIZE = min(25, max(5, int(os.getenv("STOCK_PAGE_SIZE", "40"))))
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
SUPPLY_JOB_INTERVAL = int(os.getenv("SUPPLY_JOB_INTERVAL", os.getenv("SUPPLY_JOB_INTERVAL_MINUTES", "45")))

logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.INFO),
    format="%(asctime)s %(levelname)s:%(name)s: %(message)s"
)
log = logging.getLogger("ozon-bot")
if not AUTOBOOK_ENABLED and _AUTOBOOK_IMPORT_ERROR:
    log.warning("Autobook external disabled: %s", _AUTOBOOK_IMPORT_ERROR)

DATA_DIR = Path(os.getenv("DATA_DIR", "data"))
DATA_DIR.mkdir(parents=True, exist_ok=True)
STATE_FILE = DATA_DIR / "bot_state.json"
CACHE_FILE = Path(os.getenv("SKU_CACHE_FILE", DATA_DIR / "sku_cache.json"))
HISTORY_FILE = DATA_DIR / "stock_history.json"
KEYS_DIR = DATA_DIR / "keys"; KEYS_DIR.mkdir(exist_ok=True)
GIGACHAT_TOKEN_CACHE_FILE = (DATA_DIR / GIGACHAT_TOKEN_CACHE_ENV).resolve()
SUPPLY_EVENTS_FILE = DATA_DIR / "supply_events.json"
KNOWN_USERS_FILE = DATA_DIR / "known_users.json"

if not TELEGRAM_BOT_TOKEN:
    raise SystemExit("Missing TELEGRAM_BOT_TOKEN")

MOCK_MODE = not (OZON_CLIENT_ID and OZON_API_KEY)
GIGACHAT_ENABLED = (LLM_PROVIDER == "gigachat")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher(storage=MemoryStorage())

ALLOWED_USER_IDS = _parse_ids_env("ALLOWED_USER_IDS")
ALLOWED_USERNAMES = _parse_usernames_env("ALLOWED_USERNAMES")
ACL_DENY_MESSAGE = os.getenv("ACL_DENY_MESSAGE", "").strip()
dp.update.middleware(ACLMiddleware(ALLOWED_USER_IDS, ALLOWED_USERNAMES, ACL_DENY_MESSAGE))

ADMIN_ID: Optional[int] = None
SKU_NAME_CACHE: Dict[int, str] = {}
BOT_STATE: Dict[str, Any] = {}
LAST_DEFICIT_CACHE: Dict[int, Dict[str, Any]] = {}
HISTORY_CACHE: List[dict] = []
LAST_SNAPSHOT_TS = 0
ANALYZE_LOCK = asyncio.Lock()
FACT_BUILD_LOCK = asyncio.Lock()
LAST_API_LATENCY_MS = 0.0
LAST_ANALYZE_MS = 0.0
LAST_ANALYZE_ERROR: Optional[str] = None
_HISTORY_DIRTY = False
_LAST_SAVE_FLUSH = 0.0
_GIGACHAT_TOKEN_MEM: Dict[str, Any] = {}
_LAST_AI_CALL = 0.0
FACT_INDEX: Dict[str, Any] = {}
ANSWER_CACHE: Dict[str, str] = {}
GENERAL_HISTORY: Dict[int, List[Dict[str, str]]] = {}
SUPPLY_EVENTS: Dict[str, List[Dict[str, Any]]] = {}
TASKS_CACHE: Dict[int, List[Dict[str, Any]]] = {}
APPS_CACHE: Dict[int, List[Dict[str, Any]]] = {}
WAREHOUSE_CB_MAP: Dict[str, Tuple[str,str]] = {}
LAST_PURGE_TS: Dict[int, float] = {}
KNOWN_USERS: Set[int] = set()
CROSSDOCK_SELECTED: Dict[int, Dict[str, str]] = {}  # chat_id -> {id,name}
NOTIFIED_CREATED: Set[str] = set()  # task_id, —á—Ç–æ–±—ã –Ω–µ —Å–ª–∞—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ

ENV_SKU = os.getenv("SKU_LIST", "")
if ENV_SKU:
    try:
        SKU_LIST = [int(s.strip()) for s in ENV_SKU.replace(";", ",").split(",") if s.strip()]
    except Exception:
        SKU_LIST = []
else:
    SKU_LIST = []

# ==== Cluster patterns ====
CLUSTER_MAP: Dict[str, str] = {}
RAW_CLUSTER_PATTERNS: Dict[str, List[str]] = {
    "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ –∏ –°–ó–û": [r"—Å–∞–Ω–∫—Ç", r"–ø–∏—Ç–µ—Ä", r"\b—Å–ø–±\b", r"\b—Å–∑–æ\b", r"–ª–µ–Ω–∏–Ω–≥—Ä"],
    "–ö–∞–∑–∞–Ω—å": [r"–∫–∞–∑–∞–Ω"],
    "–°–∞–º–∞—Ä–∞": [r"—Å–∞–º–∞—Ä"],
    "–£—Ñ–∞": [r"\–±—É—Ñ–∞\b"],
    "–Æ–≥": [r"\b—é–≥\b", r"—é–∂–Ω", r"—Ä–æ—Å—Ç–æ–≤", r"–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä", r"–∞—Å—Ç—Ä–∞—Ö–∞–Ω"],
    "–í–æ—Ä–æ–Ω–µ–∂": [r"–≤–æ—Ä–æ–Ω–µ–∂"],
    "–°–∞—Ä–∞—Ç–æ–≤": [r"—Å–∞—Ä–∞—Ç–æ–≤"],
    "–ö–∞–≤–∫–∞–∑": [r"–∫–∞–≤–∫–∞–∑", r"—á–µ—Ä–∫–µ—Å", r"—Å—Ç–∞–≤—Ä–æ–ø", r"–¥–∞–≥–µ—Å—Ç", r"–æ—Å–µ—Ç", r"–∏–Ω–≥—É—à", r"—á–µ—á", r"–º–∞—Ö–∞—á–∫–∞–ª"],
    "–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫": [r"–∫—Ä–∞—Å–Ω–æ—è—Ä"],
    "–°–∏–±–∏—Ä—å": [r"—Å–∏–±–∏—Ä", r"—Ç–æ–º—Å–∫", r"–æ–º—Å–∫", r"–Ω–æ–≤–æ—Å–∏–±", r"–∫–µ–º–µ—Ä–æ–≤", r"–±–∞—Ä–Ω–∞—É–ª", r"–∏—Ä–∫—É—Ç", r"–∫—É–∑–±–∞—Å"],
    "–£—Ä–∞–ª": [r"—É—Ä–∞–ª", r"–µ–∫–∞—Ç–µ—Ä–∏–Ω", r"—á–µ–ª—è–±", r"–ø–µ—Ä–º—å", r"—Å–≤–µ—Ä–¥–ª–æ–≤"],
    "–¢—é–º–µ–Ω—å": [r"—Ç—é–º–µ–Ω—å"],
    "–î–∞–ª—å–Ω–∏–π –í–æ—Å—Ç–æ–∫": [r"–¥–∞–ª—å–Ω(–∏–π)?\s*–≤–æ—Å—Ç", r"–≤–ª–∞–¥–∏–≤–æ—Å—Ç", r"—Ö–∞–±–∞—Ä–æ–≤", r"–∫–∞–º—á–∞—Ç", r"—Å–∞—Ö–∞–ª", r"–º–∞–≥–∞–¥–∞–Ω", r"—è–∫—É—Ç", r"–ø—Ä–∏–º–æ—Ä"],
    "–ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥": [r"–∫–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥"],
    "–Ø—Ä–æ—Å–ª–∞–≤–ª—å": [r"—è—Ä–æ—Å–ª–∞–≤"],
    "–ë–µ–ª–∞—Ä—É—Å—å": [r"–±–µ–ª–∞—Ä—É—Å", r"–º–∏–Ω—Å–∫", r"\b—Ä–±\b"],
    "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω": [r"–∫–∞–∑–∞—Ö—Å—Ç–∞–Ω", r"–∞–ª–º–∞—Ç—ã", r"–∞—Å—Ç–∞–Ω", r"\b–∫–∑\b", r"–∫–∞—Ä–∞–≥–∞–Ω–¥–∞"],
    "–ê—Ä–º–µ–Ω–∏—è": [r"–∞—Ä–º–µ–Ω–∏", r"–µ—Ä–µ–≤–∞–Ω"],
}
CLUSTER_PATTERN_MAP: Dict[str, List[re.Pattern]] = {
    cname: [re.compile(p, re.IGNORECASE) for p in pats]
    for cname, pats in RAW_CLUSTER_PATTERNS.items()
}

def parse_cluster_env():
    raw = WAREHOUSE_CLUSTERS_ENV
    global CLUSTER_MAP
    if not raw:
        CLUSTER_MAP = {}
        return
    try:
        obj = json.loads(raw)
        if isinstance(obj, dict):
            CLUSTER_MAP = {str(k): str(v) for k, v in obj.items()}
            return
    except Exception:
        pass
    mapping = {}
    for part in re.split(r"[;\n]+", raw):
        part = part.strip()
        if not part:
            continue
        if "=" in part or ":" in part:
            k, v = (part.split(":", 1) if ":" in part else part.split("=", 1))
            mapping[str(k).strip()] = str(v).strip().strip('"').strip("'")
    CLUSTER_MAP = mapping

parse_cluster_env()

# ==== UI constants ====
GR_FILL = {"red":"üü•","orange":"üüß","yellow":"üü®","green":"üü©"}
EMPTY_SEG="‚ñ´"
BAR_LEN=12
SEP_THIN="‚îÄ"*60
SEP_BOLD="‚ïê"*60

EMOJI_OK="‚úÖ"; EMOJI_WARN="‚ö†"; EMOJI_ANALYZE="üîç"; EMOJI_NOTIFY="üì£"; EMOJI_BOX="üì¶"
EMOJI_WH="üè¨"; EMOJI_CLUSTER="üó∫"; EMOJI_REFRESH="üîÑ"; EMOJI_TARGET="üéØ"
EMOJI_INFO="‚Ñπ"; EMOJI_DIAG="üß™"; EMOJI_AI="ü§ñ"; EMOJI_CLOUD="‚òÅ"
EMOJI_CHAT="üí¨"; EMOJI_LIST="üìÑ"; EMOJI_TASKS="üìã"

LEGEND_TEXT="–õ–µ–≥–µ–Ω–¥–∞: üü• <25%  üüß <50%  üü® <80%  üü© ‚â•80%"
AI_MAX_RENDER_LINES=420

# ==== FSM ====
class AIChatState(StatesGroup):
    waiting=State()

class AutobookStates(StatesGroup):
    choose_crossdock=State()
    after_crossdock=State()
    # –¥–∞–ª–µ–µ —à–∞–≥–∏ –≤–Ω–µ—à–Ω–µ–≥–æ –º–∞—Å—Ç–µ—Ä–∞

# ==== Formatting helpers ====
def bold(txt:str)->str:
    return f"¬ß¬ßB¬ß¬ß{txt}¬ß¬ßEB¬ß¬ß"

def build_html(lines:List[str])->str:
    text="\n".join(lines)
    text=html.escape(text)
    return (text.replace("¬ß¬ßB¬ß¬ß","<b>").replace("¬ß¬ßEB¬ß¬ß","</b>")
                .replace("¬ß¬ßI¬ß¬ß","<i>").replace("¬ß¬ßEI¬ß¬ß","</i>")
                .replace("¬ß¬ßU¬ß¬ß","<u>").replace("¬ß¬ßEU¬ß¬ß","</u>"))

def _atomic_write(path:Path, text:str):
    fd,tmp=tempfile.mkstemp(dir=str(path.parent), prefix=path.name, suffix=".tmp")
    try:
        with os.fdopen(fd,"w",encoding="utf-8") as f:
            f.write(text); f.flush(); os.fsync(f.fileno())
        os.replace(tmp,path)
    except Exception:
        try: os.unlink(tmp)
        except Exception: pass

# ==== Known users ====
def load_known_users():
    if KNOWN_USERS_FILE.exists():
        try:
            arr=json.loads(KNOWN_USERS_FILE.read_text("utf-8"))
            if isinstance(arr,list):
                for v in arr:
                    try: KNOWN_USERS.add(int(v))
                    except Exception: pass
        except Exception: pass

def save_known_users():
    try:
        tmp=str(KNOWN_USERS_FILE)+".tmp"
        with open(tmp,"w",encoding="utf-8") as f:
            json.dump(sorted(KNOWN_USERS),f,ensure_ascii=False,indent=2)
        os.replace(tmp, KNOWN_USERS_FILE)
    except Exception: pass

# ==== State persistence ====
def load_state():
    global BOT_STATE, SUPPLY_EVENTS, NOTIFIED_CREATED
    if STATE_FILE.exists():
        try:
            BOT_STATE=json.loads(STATE_FILE.read_text("utf-8"))
        except Exception:
            BOT_STATE={}
    BOT_STATE.setdefault("view_mode", DEFAULT_VIEW_MODE)
    BOT_STATE.setdefault("style_enabled", LLM_STYLE_ENABLED)
    BOT_STATE.setdefault("chat_mode", DEFAULT_CHAT_MODE if DEFAULT_CHAT_MODE in ("fact","general") else "fact")
    BOT_STATE.setdefault("cluster_view_mode", "full")
    BOT_STATE.setdefault("notified_created_ids", [])
    # –∑–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ —É–≤–µ–¥–æ–º–ª—ë–Ω–Ω—ã–µ –∑–∞—è–≤–∫–∏
    try:
        ids = BOT_STATE.get("notified_created_ids") or []
        for tid in ids:
            if tid:
                NOTIFIED_CREATED.add(str(tid))
    except Exception:
        pass
    if SUPPLY_EVENTS_FILE.exists():
        try:
            SUPPLY_EVENTS.update(json.loads(SUPPLY_EVENTS_FILE.read_text("utf-8")))
        except Exception:
            pass
    SUPPLY_EVENTS.setdefault("*", [])

def save_state():
    try:
        BOT_STATE["notified_created_ids"] = sorted(list(NOTIFIED_CREATED))
        _atomic_write(STATE_FILE, json.dumps(BOT_STATE, ensure_ascii=False, indent=2))
    except Exception as e: log.warning("save_state error: %s", e)

def load_cache():
    global SKU_NAME_CACHE
    if Path(CACHE_FILE).exists():
        try:
            data=json.loads(Path(CACHE_FILE).read_text("utf-8"))
            SKU_NAME_CACHE={int(k):v for k,v in data.items()}
        except Exception:
            SKU_NAME_CACHE={}

def save_cache_if_needed(prev:int):
    if len(SKU_NAME_CACHE)>prev:
        try: _atomic_write(Path(CACHE_FILE), json.dumps(SKU_NAME_CACHE, ensure_ascii=False, indent=2))
        except Exception as e: log.warning("cache save error: %s", e)

def load_history():
    global HISTORY_CACHE, LAST_SNAPSHOT_TS
    if HISTORY_FILE.exists():
        try:
            arr=json.loads(HISTORY_FILE.read_text("utf-8"))
            if isinstance(arr,list): HISTORY_CACHE[:]=arr
        except Exception as e:
            log.warning("history load error: %s", e)
    if HISTORY_CACHE:
        LAST_SNAPSHOT_TS=max(s.get("ts",0) for s in HISTORY_CACHE)

def mark_history_dirty():
    global _HISTORY_DIRTY
    _HISTORY_DIRTY=True

async def flush_history_if_needed(force=False):
    global _HISTORY_DIRTY, _LAST_SAVE_FLUSH
    if not _HISTORY_DIRTY and not force:
        return
    now=time.time()
    if force or (now-_LAST_SAVE_FLUSH>SAVE_BUFFER_FLUSH_SECONDS):
        try:
            await asyncio.to_thread(_atomic_write, HISTORY_FILE, json.dumps(HISTORY_CACHE, ensure_ascii=False))
            _HISTORY_DIRTY=False
            _LAST_SAVE_FLUSH=now
        except Exception as e:
            log.warning("history flush error: %s", e)

def prune_history():
    cutoff=int(time.time())-HISTORY_RETENTION_DAYS*86400
    before=len(HISTORY_CACHE)
    if not before: return
    pruned=[s for s in HISTORY_CACHE if s.get("ts",0)>=cutoff]
    if len(pruned)>MAX_HISTORY_SNAPSHOTS:
        pruned=pruned[-MAX_HISTORY_SNAPSHOTS:]
    if len(pruned)!=before:
        HISTORY_CACHE[:]=pruned
        mark_history_dirty()
        log.info("History pruned %d -> %d", before, len(pruned))

def append_snapshot(rows:List[Dict]):
    global LAST_SNAPSHOT_TS
    ts=int(time.time()); nr=[]
    for r in rows:
        try:
            sku=int(r.get("sku") or 0)
            if not sku: continue
            wid_raw=r.get("warehouse_id")
            wname=(r.get("warehouse_name") or (r.get("warehouse") or {}).get("name") or (str(wid_raw) if wid_raw else "–°–∫–ª–∞–¥"))
            qty=int(r.get("free_to_sell_amount") or 0)
            if qty<0: qty=0
            wkey=str(wid_raw) if wid_raw not in (None,"") else f"name:{wname}"
            nr.append({"sku":sku,"warehouse_key":wkey,"warehouse_name":wname,"qty":qty})
        except Exception:
            continue
    HISTORY_CACHE.append({"ts":ts,"rows":nr})
    LAST_SNAPSHOT_TS=ts
    mark_history_dirty()

def _persist_supply_events():
    try:
        _atomic_write(SUPPLY_EVENTS_FILE, json.dumps(SUPPLY_EVENTS, ensure_ascii=False, indent=2))
    except Exception as e:
        log.warning("supply events save error: %s", e)

def _supply_log_append(chat_id:int, entry:Dict[str,Any]):
    arr=SUPPLY_EVENTS.setdefault(str(chat_id), [])
    arr.append(entry)
    SUPPLY_EVENTS.setdefault("*", []).append(entry)
    for k in (str(chat_id),"*"):
        a=SUPPLY_EVENTS.get(k,[])
        if len(a)>1000:
            del a[0:len(a)-1000]
    # –ê–≤—Ç–æ-—Å–ª–æ—Ç: –µ—Å–ª–∏ –∑–∞–¥–∞—á–∞ –Ω–∞ WAIT_WINDOW/CREATING ‚Äî –≤–∫–ª—é—á–∞–µ–º auto_watch –∏ —Å—Ç–∞–≤–∏–º –≤ –æ—á–µ—Ä–µ–¥—å
    try:
        payload=entry.get("payload") or {}
        status=(entry.get("status") or "DRAFT").upper()
        tid=payload.get("id") or payload.get("task_id")
        if tid and status in ("WAIT_WINDOW","CREATING","CREATED","NEW","INITIAL"):
            try:
                import supply_watch as swm
                if hasattr(swm, "set_auto_watch_for_task"):
                    swm.set_auto_watch_for_task(tid, True)
                if hasattr(swm, "enqueue_task_watch"):
                    swm.enqueue_task_watch(tid)
            except Exception:
                pass
    except Exception:
        pass
    _persist_supply_events()

# ==== Name fetch / API ====
async def ozon_stock_fbo(skus:List[int])->Tuple[List[Dict],Optional[str]]:
    if not skus: return [], "SKU_LIST –ø—É—Å—Ç"
    if MOCK_MODE:
        demo_wh=[(1,"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ –§–ë–û"),(2,"–ö–∞–∑–∞–Ω—å")]
        rows=[]
        for sku in skus:
            for wid,name in demo_wh:
                rows.append({"sku":sku,"warehouse_id":wid,"warehouse_name":name,"free_to_sell_amount":(sku%37)+wid*5})
        return rows,None
    url="https://api-seller.ozon.ru/v2/analytics/stock_on_warehouses"
    payload={"sku":skus,"limit":1000,"offset":0}
    headers={"Client-Id":OZON_CLIENT_ID,"Api-Key":OZON_API_KEY,"Content-Type":"application/json"}
    start=time.time()
    try:
        async with httpx.AsyncClient(timeout=API_TIMEOUT_SECONDS, trust_env=True) as client:
            resp=await client.post(url,json=payload,headers=headers)
    except Exception as e:
        return [], f"HTTP error: {e}"
    finally:
        global LAST_API_LATENCY_MS
        LAST_API_LATENCY_MS=(time.time()-start)*1000
    if resp.status_code!=200:
        try: data=resp.json(); msg=data.get("message") or data.get("error") or resp.text
        except Exception: msg=resp.text
        return [], f"Ozon API {resp.status_code}: {msg}"
    try: data=resp.json()
    except Exception: return [], "Non-JSON response"
    rows=[]
    if isinstance(data,dict):
        res=data.get("result")
        if isinstance(res,dict) and isinstance(res.get("rows"),list):
            rows=res["rows"]
        elif isinstance(data.get("rows"),list):
            rows=data["rows"]
        else:
            for v in data.values():
                if isinstance(v,list) and v and isinstance(v[0],dict):
                    rows=v; break
    return rows or [], None

async def _fetch_names_batch(skus:List[int])->Dict[int,str]:
    headers={"Client-Id":OZON_CLIENT_ID,"Api-Key":OZON_API_KEY,"Content-Type":"application/json"}
    out={}
    if not skus: return out
    url="https://api-seller.ozon.ru/v3/product/info/list"
    payload={"sku": skus}
    try:
        async with httpx.AsyncClient(timeout=API_TIMEOUT_SECONDS, trust_env=True) as client:
            resp=await client.post(url,json=payload,headers=headers)
        if resp.status_code!=200:
            log.warning("Name batch fetch status=%s body=%s", resp.status_code, resp.text[:300])
            return out
        js=resp.json()
        items=(js.get("result") or {}).get("items") or js.get("items") or (js.get("result") if isinstance(js.get("result"),list) else [])
        if not isinstance(items,list):
            items=[]
        for it in items:
            try:
                sku=int(it.get("sku") or it.get("offer_id") or 0)
            except Exception:
                continue
            nm=it.get("name") or it.get("title") or it.get("display_name") or it.get("product_name") or f"SKU {sku}"
            out[sku]=nm
    except Exception as e:
        log.warning("Batch name error: %s", e)
    return out

async def _fetch_name_single(sku:int)->str:
    headers={"Client-Id":OZON_CLIENT_ID,"Api-Key":OZON_API_KEY,"Content-Type":"application/json"}
    # Try v2 by offer_id
    url="https://api-seller.ozon.ru/v2/product/info"
    payload={"offer_id": str(sku)}
    try:
        async with httpx.AsyncClient(timeout=API_TIMEOUT_SECONDS, trust_env=True) as client:
            r=await client.post(url,json=payload,headers=headers)
        if r.status_code==200:
            js=r.json()
            nm=js.get("result",{}).get("name") or js.get("name")
            if nm: return nm
    except Exception:
        pass
    # Try v3 with single sku list
    payload={"sku": [sku]}
    try:
        async with httpx.AsyncClient(timeout=API_TIMEOUT_SECONDS, trust_env=True) as client:
            r=await client.post("https://api-seller.ozon.ru/v3/product/info/list",json=payload,headers=headers)
        if r.status_code==200:
            js=r.json()
            items=(js.get("result") or {}).get("items") or []
            for it in items:
                if int(it.get("sku") or 0)==sku:
                    nm=it.get("name") or it.get("title")
                    if nm: return nm
    except Exception:
        pass
    return f"SKU {sku}"

async def ozon_product_names_by_sku(skus:List[int])->Tuple[Dict[int,str],Optional[str]]:
    if not skus: return {}, None
    if MOCK_MODE:
        return {s:f"Demo SKU {s}" for s in skus}, None
    unique=[s for s in skus if s>0]
    mapping={}
    CHUNK=100
    for i in range(0,len(unique),CHUNK):
        chunk=unique[i:i+CHUNK]
        batch=await _fetch_names_batch(chunk)
        mapping.update(batch)
    missing=[s for s in unique if s not in mapping]
    for sku in missing[:80]:
        mapping[sku]=await _fetch_name_single(sku)
    for s in unique:
        mapping.setdefault(s,f"SKU {s}")
    return mapping, None

def skus_needing_names()->List[int]:
    return [s for s in SKU_LIST if (s not in SKU_NAME_CACHE) or SKU_NAME_CACHE[s].startswith("SKU ") or SKU_NAME_CACHE[s].lower().startswith("demo sku")]

async def ensure_sku_names(force:bool=False):
    to_fetch = SKU_LIST if force else skus_needing_names()
    if to_fetch:
        prev=len(SKU_NAME_CACHE)
        mp,_=await ozon_product_names_by_sku(to_fetch)
        SKU_NAME_CACHE.update(mp)
        save_cache_if_needed(prev)

def get_sku_name_local(sku:int)->str:
    return SKU_NAME_CACHE.get(sku, f"SKU {sku}")

# –õ–µ–Ω–∏–≤—ã–π —Ä–µ–∑–æ–ª–≤–µ—Ä –∏–º—ë–Ω –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –º–∞—Å—Ç–µ—Ä–∞: –µ—Å–ª–∏ –∏–º–µ–Ω–∏ –Ω–µ—Ç ‚Äî –ø–æ–¥–∫–∞—á–∏–≤–∞–µ–º –≤ —Ñ–æ–Ω–µ
def get_or_fetch_sku_name_lazy(sku: int) -> str:
    name = SKU_NAME_CACHE.get(sku)
    if name and not name.lower().startswith("sku "):
        return name

    async def _fetch_one(_sku: int):
        try:
            mp, _ = await ozon_product_names_by_sku([_sku])
            if mp and _sku in mp:
                prev = len(SKU_NAME_CACHE)
                SKU_NAME_CACHE[_sku] = mp[_sku]
                save_cache_if_needed(prev)
        except Exception as e:
            log.warning("lazy name fetch failed for %s: %s", _sku, e)

    try:
        loop = asyncio.get_running_loop()
        loop.create_task(_fetch_one(int(sku)))
    except Exception:
        pass
    return f"SKU {sku}"

def try_mount_external_name_resolver():
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º –≤–æ –≤–Ω–µ—à–Ω–∏–π –º–æ–¥—É–ª—å –ª–µ–Ω–∏–≤—ã–π —Ä–µ–∑–æ–ª–≤–µ—Ä –∏–º—ë–Ω
    if not AUTOBOOK_ENABLED:
        return

    def resolver(s):
        try:
            sk = int(s)
        except Exception:
            return ""
        return get_or_fetch_sku_name_lazy(sk)

    candidates = [
        "set_name_resolver", "set_sku_name_resolver", "set_sku_title_provider",
        "set_title_resolver", "register_name_resolver"
    ]
    mounted=False
    for fn in candidates:
        if hasattr(abf, fn):
            try:
                getattr(abf, fn)(resolver)
                log.info("Autobook: name resolver mounted via %s", fn)
                mounted=True
                break
            except Exception as e:
                log.warning("Autobook: mount resolver failed (%s): %s", fn, e)
    if not mounted:
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∫–∞–∫ –∞—Ç—Ä–∏–±—É—Ç
        for attr in ("SKU_TITLE_PROVIDER","NAME_RESOLVER","TITLE_RESOLVER"):
            try:
                setattr(abf, attr, resolver)
                log.info("Autobook: resolver set attr %s", attr)
                mounted=True
                break
            except Exception:
                pass
    if not mounted:
        log.info("Autobook: no compatible name resolver interface exposed; fallback to SKU will remain in external UI.")

# ==== Consumption / Index helpers ====
def build_consumption_cache()->Dict[Tuple[int,str],Dict[str,Any]]:
    now=int(time.time()); cutoff=now-HISTORY_LOOKBACK_DAYS*86400
    series={}
    for snap in HISTORY_CACHE:
        ts=snap.get("ts",0)
        if ts<cutoff: continue
        for r in snap.get("rows",[]):
            sku=r.get("sku"); wkey=r.get("warehouse_key"); qty=r.get("qty")
            if sku is None or wkey is None: continue
            try: sku_i=int(sku); qty_i=int(qty)
            except Exception: continue
            series.setdefault((sku_i,wkey),[]).append((ts,qty_i))
    cache={}
    for key,arr in series.items():
        arr.sort(key=lambda x:x[0])
        if MAX_HISTORY_POINTS>0 and len(arr)>MAX_HISTORY_POINTS:
            arr=arr[-MAX_HISTORY_POINTS:]
        points=len(arr); total_decrease=0
        if points>=2:
            span=arr[-1][0]-arr[0][0]
            if span>0:
                span_hours=span/3600
                for i in range(1,points):
                    p=arr[i-1][1]; c=arr[i][1]
                    if p>c: total_decrease+=p-c
                if span_hours>=MIN_HISTORY_HOURS and total_decrease>0:
                    avg_per_hour=total_decrease/span_hours
                    monthly=avg_per_hour*24*30
                    norm=max(1, math.ceil(monthly))
                    target=max(norm+1, math.ceil(norm*TARGET_MULTIPLIER))
                    cache[key]={"norm":norm,"target":target,"history_used":True}
                    continue
        norm=MIN_STOCK; target=int(MIN_STOCK*TARGET_MULTIPLIER)
        cache[key]={"norm":norm,"target":target,"is_low":False,"history_used":False}
    return cache

def evaluate_position_cached(sku:int,wkey:str,qty:int,ccache:Dict[Tuple[int,str],Dict[str,Any]])->Dict[str,Any]:
    meta=ccache.get((sku,wkey))
    if not meta:
        norm=MIN_STOCK; target=int(MIN_STOCK*TARGET_MULTIPLIER)
        return {"norm":norm,"target":target,"is_low":qty<norm,"need":max(0,norm-qty) if qty<norm else 0,"history_used":False}
    norm=meta["norm"]; target=meta["target"]; is_low=qty<norm
    return {"norm":norm,"target":target,"is_low":is_low,"need":max(0,norm-qty) if is_low else 0,"history_used":meta["history_used"]}

def aggregate_rows(rows:List[Dict])->Dict[int,Dict[str,Dict[str,Any]]]:
    agg={}
    for r in rows:
        try:
            sku=int(r.get("sku") or 0)
            if sku==0: continue
            qty=int(r.get("free_to_sell_amount") or r.get("qty") or 0)
            if qty<0: qty=0
            wid_raw=r.get("warehouse_id")
            wname=r.get("warehouse_name") or (r.get("warehouse") or {}).get("name") or (str(wid_raw) if wid_raw else "–°–∫–ª–∞–¥")
            wkey=str(wid_raw) if wid_raw not in (None,"") else f"name:{wname}"
        except Exception:
            continue
        agg.setdefault(sku,{})
        agg[sku].setdefault(wkey,{"qty":0,"warehouse_name":wname})
        agg[sku][wkey]["qty"]+=qty
    return agg

def coverage_bar(r:float)->Tuple[str,str]:
    if r<0: r=0
    if r<0.25: c=GR_FILL["red"]; sev="–ö—Ä–∏—Ç–∏—á–Ω–æ"
    elif r<0.5: c=GR_FILL["orange"]; sev="–ö—Ä–∏—Ç–∏—á–Ω–æ"
    elif r<0.8: c=GR_FILL["yellow"]; sev="–ù–∏–∂–µ –Ω–æ—Ä–º—ã"
    else: c=GR_FILL["green"]; sev="–ù–æ—Ä–º–∞–ª—å–Ω–æ"
    filled=min(BAR_LEN,max(0,round(r*BAR_LEN)))
    bar=c*filled+EMPTY_SEG*(BAR_LEN-filled)
    return f"{bar} {int(r*100):02d}%", sev

def calc_need_pct(qty:int, norm:int, target:int)->Tuple[int,int]:
    p_norm=int(round(max(0, (norm-qty))/norm*100)) if norm>0 else 0
    p_target=int(round(max(0, (target-qty))/target*100)) if target>0 else 0
    return max(0,min(100,p_norm)), max(0,min(100,p_target))

def need_pct_text(qty:int, norm:int, target:int)->str:
    pn, pt = calc_need_pct(qty, norm, target)
    return f"{pn}% –¥–æ –Ω–æ—Ä–º—ã / {pt}% –¥–æ —Ü–µ–ª–∏"

# ==== Cluster functions ====
def resolve_cluster_for_warehouse(wkey:str,wname:str)->str:
    if CLUSTER_MAP:
        raw_id=None if wkey.startswith("name:") else wkey
        if raw_id and raw_id in CLUSTER_MAP: return CLUSTER_MAP[raw_id]
        if wname in CLUSTER_MAP: return CLUSTER_MAP[wname]
        return "–ü—Ä–æ—á–∏–µ"
    lname=(wname or "").lower()
    for cname,pats in CLUSTER_PATTERN_MAP.items():
        for p in pats:
            if p.search(lname): return cname
    return "–ü—Ä–æ—á–∏–µ"

def aggregate_clusters_from_fact(sku_section:Dict[int,Any])->Dict[str,Any]:
    clusters={}
    for sku,data in sku_section.items():
        for w in data.get("warehouses", []):
            cname=resolve_cluster_for_warehouse(w["wkey"], w["name"])
            c=clusters.setdefault(cname,{
                "name":cname,"total_qty":0,"total_need_target":0,"deficit_need":0,"sku_set":set(),
                "critical_sku":0,"mid_sku":0,"ok_sku":0,"warehouses":set()
            })
            qty=w["qty"]; gap_target=max(0,w["target"]-w["qty"])
            c["total_qty"]+=qty; c["total_need_target"]+=gap_target; c["deficit_need"]+=w["need"]
            c["warehouses"].add(w["name"]); c["sku_set"].add(sku)
            cov=w["coverage"]
            if cov<0.5: c["critical_sku"]+=1
            elif cov<0.8: c["mid_sku"]+=1
            else: c["ok_sku"]+=1
    out={}
    for cname,meta in clusters.items():
        out[cname]={
            "name":cname,
            "total_qty":meta["total_qty"],
            "total_need_target":meta["total_need_target"],
            "deficit_need":meta["deficit_need"],
            "total_sku":len(meta["sku_set"]),
            "critical_sku":meta["critical_sku"],
            "mid_sku":meta["mid_sku"],
            "ok_sku":meta["ok_sku"],
            "warehouses":sorted(meta["warehouses"])
        }
    return out

def small_cov_bar(cov:float,length:int=12)->str:
    cov=max(0.0,min(1.0,cov))
    if cov<0.25: color=GR_FILL["red"]
    elif cov<0.5: color=GR_FILL["orange"]
    elif cov<0.8: color=GR_FILL["yellow"]
    else: color=GR_FILL["green"]
    filled=max(1,round(cov*length))
    return color*filled+EMPTY_SEG*(length-filled)

def build_cluster_detail(name:str, cluster_section:Dict[str,Any], sku_section:Dict[int,Any], short:bool=False)->str:
    cl=cluster_section.get(name)
    if not cl:
        return build_html([f"{EMOJI_CLUSTER} –ö–ª–∞—Å—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω."])
    wh_stats={}
    for sku, skud in sku_section.items():
        for w in skud.get("warehouses", []):
            if resolve_cluster_for_warehouse(w["wkey"], w["name"]) != name:
                continue
            ws=wh_stats.setdefault(w["wkey"], {
                "name": w["name"],"total_qty":0,"need_norm":0,"need_target":0,
                "critical_sku":0,"mid_sku":0,"ok_sku":0,"sku_set":set()
            })
            ws["total_qty"]+=w["qty"]; ws["need_norm"]+=w["need"]; ws["need_target"]+=max(0,w["target"]-w["qty"])
            ws["sku_set"].add(sku)
            cov=w["coverage"]
            if cov<0.5: ws["critical_sku"]+=1
            elif cov<0.8: ws["mid_sku"]+=1
            else: ws["ok_sku"]+=1

    wh_items={}
    for sku, skud in sku_section.items():
        for w in skud.get("warehouses", []):
            if resolve_cluster_for_warehouse(w["wkey"], w["name"]) != name:
                continue
            if w["need"]<=0: continue
            arr=wh_items.setdefault(w["wkey"], [])
            arr.append({
                "sku":sku,"name":skud["name"],"qty":w["qty"],
                "norm":w["norm"],"target":w["target"],"need":w["need"],"coverage":w["coverage"]
            })
    for wk in wh_items:
        wh_items[wk].sort(key=lambda x:(x["coverage"], -x["need"]))

    cov_worst=[]
    for sku, skud in sku_section.items():
        worst=1.0; inside=False
        for w in skud.get("warehouses", []):
            if resolve_cluster_for_warehouse(w["wkey"], w["name"])==name:
                worst=min(worst,w["coverage"]); inside=True
        if inside: cov_worst.append(worst)
    cluster_worst=min(cov_worst) if cov_worst else 0.0
    cluster_avg=(sum(cov_worst)/len(cov_worst)) if cov_worst else 0.0

    lines=[f"üó∫ ¬ß¬ßB¬ß¬ß–ö–ª–∞—Å—Ç–µ—Ä: {name}¬ß¬ßEB¬ß¬ß", SEP_THIN,
           f"SKU –≤—Å–µ–≥–æ: {cl['total_sku']}",
           f"–°—É–º–º–∞—Ä–Ω—ã–π –æ—Å—Ç–∞—Ç–æ–∫: {cl['total_qty']}",
           f"–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –¥–æ —Ü–µ–ª–∏: {cl['total_need_target']}",
           f"–î–µ—Ñ–∏—Ü–∏—Ç (–Ω–∏–∂–µ –Ω–æ—Ä–º—ã): {cl['deficit_need']}",
           "", "–ü–æ–∫—Ä—ã—Ç–∏–µ:",
           f"  –•—É–¥—à–µ–µ: {small_cov_bar(cluster_worst,20)} {int(cluster_worst*100):02d}%",
           f"  –°—Ä–µ–¥–Ω–µ–µ: {small_cov_bar(cluster_avg,20)} {int(cluster_avg*100):02d}%",
           SEP_THIN]

    wh_sorted=sorted(wh_stats.values(), key=lambda x:x["need_target"], reverse=True)
    if not short:
        lines+=["¬ß¬ßB¬ß¬ß–°–≤–æ–¥–∫–∞ –ø–æ —Å–∫–ª–∞–¥–∞–º¬ß¬ßEB¬ß¬ß"]
        if wh_sorted:
            header=f"{'–°–∫–ª–∞–¥':<30} {'SKU':>4} {'–û—Å—Ç–∞—Ç–æ–∫':>8} {'–î–µ—Ñ–∏—Ü–∏—Ç':>8} {'–î–æ —Ü–µ–ª–∏':>8} {'–ö—Ä–∏—Ç–∏—á–Ω—ã—Ö':>10}"
            lines.append(header); lines.append("-"*len(header))
            for ws in wh_sorted[:40]:
                lines.append(f"{ws['name'][:30]:<30} {len(ws['sku_set']):>4} {ws['total_qty']:>8} {ws['need_norm']:>8} {ws['need_target']:>8} {ws['critical_sku']:>10}")
        else:
            lines.append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        lines.append(SEP_THIN)
    else:
        lines.append("¬ß¬ßB¬ß¬ß–°–∫–ª–∞–¥—ã (–∫–æ—Ä–æ—Ç–∫–æ)¬ß¬ßEB¬ß¬ß")
        if wh_sorted:
            for ws in wh_sorted[:12]:
                lines.append(f"‚Ä¢ {ws['name']}: –¥–µ—Ñ–∏—Ü–∏—Ç {ws['need_norm']}, –¥–æ —Ü–µ–ª–∏ {ws['need_target']}, –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö {ws['critical_sku']}")
        else: lines.append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        lines.append(SEP_THIN)

    lines.append("¬ß¬ßB¬ß¬ß–¢–æ–≤–∞—Ä—ã –ø–æ —Å–∫–ª–∞–¥–∞–º (–¥–µ—Ñ–∏—Ü–∏—Ç)¬ß¬ßEB¬ß¬ß"+(" (–∫–æ—Ä–æ—Ç–∫–æ)" if short else ""))
    if not wh_sorted:
        lines.append("–ù–µ—Ç —Å–∫–ª–∞–¥–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ.")
    else:
        per_wh_limit=12 if not short else 6
        for ws in wh_sorted:
            wkey=None
            for k,meta in wh_stats.items():
                if meta is ws:
                    wkey=k; break
            if wkey is None:
                for k,meta in wh_stats.items():
                    if meta["name"]==ws["name"]:
                        wkey=k; break
            lines.append(f"{EMOJI_WH} {bold(ws['name'])} ‚Äî –û—Å—Ç–∞—Ç–æ–∫ {ws['total_qty']} | –î–µ—Ñ–∏—Ü–∏—Ç {ws['need_norm']} | –î–æ —Ü–µ–ª–∏ {ws['need_target']}")
            items=wh_items.get(wkey,[])
            if not items:
                lines.append("  ‚Ä¢ –î–µ—Ñ–∏—Ü–∏—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            else:
                for it in items[:per_wh_limit]:
                    cov=it["qty"]/it["norm"] if it["norm"] else 0
                    bar, sev=coverage_bar(cov)
                    badge=need_pct_text(it["qty"], it["norm"], it["target"])
                    lines.append(f"  ‚Ä¢ {bold(it['name'])} (SKU {it['sku']})")
                    lines.append(f"    –û—Å—Ç–∞—Ç–æ–∫ {it['qty']} / –ù–æ—Ä–º–∞ {it['norm']} / –¶–µ–ª—å {it['target']} ‚Üí +{it['need']} ¬∑ {badge}")
                    lines.append(f"    {bar} {sev}")
            lines.append(SEP_THIN)
    return build_html(lines)

# ==== FACT INDEX ====
def build_fact_index(rows:List[dict], flat:List[dict], ccache:Dict[Tuple[int,str],Dict[str,Any]]):
    agg=aggregate_rows(rows)
    sku_section={}
    wh_agg={}
    for sku,wmap in agg.items():
        name=SKU_NAME_CACHE.get(sku,f"SKU {sku}")
        entry={"name":name,"total_qty":0,"total_need":0,"deficit_need":0,"worst_coverage":1.0,"warehouses":[]}
        for wkey,info in wmap.items():
            qty=info["qty"]
            st=evaluate_position_cached(sku,wkey,qty,ccache)
            norm=st["norm"] or 1
            coverage=qty/norm if norm else 0
            need_def=st["need"] if st["is_low"] else 0
            gap_target=max(0, st["target"]-qty)
            entry["total_qty"]+=qty
            entry["deficit_need"]+=need_def
            entry["total_need"]+=gap_target
            entry["worst_coverage"]=min(entry["worst_coverage"], coverage)
            entry["warehouses"].append({
                "wkey":wkey,"name":info["warehouse_name"],"qty":qty,"norm":st["norm"],"target":st["target"],
                "need":need_def,"coverage":round(coverage,4),"history_used":st["history_used"]
            })
            wm=wh_agg.setdefault(wkey,{"name":info["warehouse_name"],"total_qty":0,"total_need":0,"deficit_need":0,
                                       "sku_set":set(),"critical_sku":0,"mid_sku":0,"ok_sku":0})
            wm["total_qty"]+=qty; wm["total_need"]+=gap_target; wm["deficit_need"]+=need_def
            wm["sku_set"].add(sku)
            if coverage<0.5: wm["critical_sku"]+=1
            elif coverage<0.8: wm["mid_sku"]+=1
            else: wm["ok_sku"]+=1
        entry["warehouses"].sort(key=lambda x:x["coverage"])
        sku_section[sku]=entry
    top_deficits=sorted(
        ({"sku":s,"name":v["name"],"coverage":round(v["worst_coverage"],4),"deficit_need":v["deficit_need"]}
         for s,v in sku_section.items()),
        key=lambda x:x["coverage"]
    )[:LLM_TOP_DEFICITS]
    wh_section={}
    for k,meta in wh_agg.items():
        wh_section[k]={
            "name":meta["name"],"total_qty":meta["total_qty"],
            "total_need":meta["total_need"],"deficit_need":meta["deficit_need"],
            "total_sku":len(meta["sku_set"]),
            "critical_sku":meta["critical_sku"],
            "mid_sku":meta["mid_sku"],
            "ok_sku":meta["ok_sku"]
        }
    cluster_section=aggregate_clusters_from_fact(sku_section)
    top_clusters=sorted(
        ({"cluster":c,"name":v["name"],"total_need":v["total_need_target"],"deficit_need":v["deficit_need"]}
         for c,v in cluster_section.items()),
        key=lambda x:x["total_need"], reverse=True
    )[:LLM_TOP_CLUSTERS]
    top_warehouses=sorted(
        ({"wkey":k,"name":v["name"],"total_need":v["total_need"],"deficit_need":v["deficit_need"]}
         for k,v in wh_section.items()),
        key=lambda x:x["total_need"], reverse=True
    )[:LLM_TOP_WAREHOUSES]
    sample=[f"{sku}:{sku_section[sku]['name'][:50]}" for sku in sorted(sku_section.keys())[:LLM_INVENTORY_SAMPLE_SKU]]
    FACT_INDEX.clear()
    FACT_INDEX.update({
        "updated_ts":int(time.time()),
        "snapshot_ts":LAST_SNAPSHOT_TS,
        "sku":sku_section,
        "warehouse":wh_section,
        "cluster":cluster_section,
        "top_deficits":top_deficits,
        "top_warehouses":top_warehouses,
        "top_clusters":top_clusters,
        "inventory_overview":{"total_sku":len(sku_section),"sample_skus":sample}
    })

async def ensure_fact_index(force:bool=False, silent:bool=True):
    async with FACT_BUILD_LOCK:
        if not force and FACT_INDEX:
            return
        if not SKU_LIST:
            return
        rows, err = await ozon_stock_fbo(SKU_LIST)
        if err:
            log.warning("ensure_fact_index: Ozon error: %s", err)
            return
        if time.time()-LAST_SNAPSHOT_TS>SNAPSHOT_MIN_REUSE_SECONDS:
            append_snapshot(rows)
        await ensure_sku_names(force=True)  # –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–¥ –∏–Ω–¥–µ–∫—Å–æ–º
        ccache=build_consumption_cache()
        try:
            build_fact_index(rows, [], ccache)
        except Exception as e:
            log.exception("ensure_fact_index build error: %s", e)
        await flush_history_if_needed(force=True)
        if not silent and ADMIN_ID:
            await send_safe_message(ADMIN_ID, "–ò–Ω–¥–µ–∫—Å –æ–±–Ω–æ–≤–ª—ë–Ω.", disable_web_page_preview=True)

# ==== Deficit report ====
def generate_deficit_report(rows:List[Dict], name_map:Dict[int,str], ccache:Dict[Tuple[int,str],Dict[str,Any]])->Tuple[str,List[dict]]:
    agg=aggregate_rows(rows)
    deficits={}; flat=[]
    for sku,wmap in agg.items():
        for wkey,info in wmap.items():
            qty=info["qty"]; st=evaluate_position_cached(sku,wkey,qty,ccache)
            if st["is_low"]:
                cov=qty/st["norm"] if st["norm"] else 0
                d={"sku":sku,"name":name_map.get(sku,f"SKU {sku}"),"warehouse_key":wkey,"warehouse_name":info["warehouse_name"],
                   "qty":qty,"norm":st["norm"],"target":st["target"],"need":st["need"],
                   "coverage":cov,"history_used":st["history_used"]}
                deficits.setdefault(sku,[]).append(d)
                flat.append(d)
    if not deficits:
        return f"{EMOJI_OK} –ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∏–∂–µ –Ω–æ—Ä–º—ã.", []
    sku_order=sorted(deficits.keys(), key=lambda s: min(x["coverage"] for x in deficits[s]))
    view_mode=BOT_STATE.get("view_mode", DEFAULT_VIEW_MODE)
    full=(view_mode=="FULL")
    crit=mid=hi=0
    lines=[f"{EMOJI_ANALYZE} ¬ß¬ßB¬ß¬ß–î–µ—Ñ–∏—Ü–∏—Ç –ø–æ —Ç–æ–≤–∞—Ä–∞–º¬ß¬ßEB¬ß¬ß", LEGEND_TEXT, SEP_BOLD]
    for sku in sku_order:
        items=deficits[sku]; items.sort(key=lambda x:x["coverage"])
        pname=items[0]["name"]; worst=min(i["coverage"] for i in items)
        head="üî•" if worst<0.25 else (EMOJI_WARN if worst<0.5 else "‚û§")
        lines.append(f"{head} ¬ß¬ßB¬ß¬ß{pname} (SKU {sku})¬ß¬ßEB¬ß¬ß")
        total_qty=sum(i["qty"] for i in items); total_need=sum(i["need"] for i in items)
        for i in items:
            bar,sev=coverage_bar(i["coverage"])
            if i["coverage"]<0.5: crit+=1
            elif i["coverage"]<0.8: mid+=1
            else: hi+=1
            hist="(–∏—Å—Ç–æ—Ä–∏—è)" if i["history_used"] else "(–º–∏–Ω. –ø–æ—Ä–æ–≥)"
            badge=need_pct_text(i["qty"], i["norm"], i["target"])
            wh_b=bold(i['warehouse_name'])
            if full:
                lines.append(f"‚Ä¢ {wh_b}: –û—Å—Ç–∞—Ç–æ–∫ {i['qty']} / –ù–æ—Ä–º–∞ {i['norm']} / –¶–µ–ª—å {i['target']} ‚Üí +{i['need']}\n  {bar} {sev} {hist} ¬∑ {badge}")
            else:
                lines.append(f"‚Ä¢ {wh_b}: –û—Å—Ç–∞—Ç–æ–∫ {i['qty']} ‚Üí +{i['need']}  {bar} ¬∑ {badge}")
        lines.append(f"  Œ£ –û—Å—Ç–∞—Ç–æ–∫={total_qty}, –ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å (–¥–æ –Ω–æ—Ä–º—ã)={total_need}")
        lines.append(SEP_THIN)
    lines.append(f"{EMOJI_TARGET} –ò—Ç–æ–≥–∏: —Ç–æ–≤–∞—Ä–æ–≤={len(deficits)}, —Å—Ç—Ä–æ–∫={len(flat)} | <50%={crit} | 50‚Äì80%={mid} | ‚â•80% –Ω–æ –Ω–∏–∂–µ –Ω–æ—Ä–º—ã={hi} | —Ä–µ–∂–∏–º={view_mode}")
    return build_html(lines), flat

# ==== AI highlight & answer ====
HIGHLIGHT_PATTERNS=[
    (r"(\b\d{1,3}(?:[\s.,]\d{3})+|\b\d+)\b","num"),
    (r"\b\d{1,3}%\b","pct"),
    (r"\b(SKU\s*\d+)\b","sku"),
    (r"\b(–¥–µ—Ñ–∏—Ü–∏—Ç\w*)\b","kw"),
    (r"\b(—Å–∫–ª–∞–¥\w*)\b","kw"),
    (r"\b(–∫–ª–∞—Å—Ç–µ—Ä\w*)\b","kw"),
    (r"\b(–Ω–æ—Ä–º[–∞–∏—ã]?)\b","kw"),
    (r"\b(—Ü–µ–ª—å|target|—Ü–µ–ª–µ–≤–∞—è)\b","kw"),
    (r"\b(–ø–æ–∫—Ä—ã—Ç–∏[–µ—è]|coverage)\b","kw"),
]

def _html_highlight(text:str)->str:
    def repl_bold(m): return f"<b>{html.escape(m.group(1))}</b>"
    out=text
    for pat,_ in HIGHLIGHT_PATTERNS:
        out=re.sub(pat,repl_bold,out,flags=re.IGNORECASE)
    return out

def style_ai_answer(question:str, raw:str, mode:str, fact_mode:bool)->str:
    raw=(raw or "").strip() or "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞."
    header=f"{EMOJI_AI} <b>–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞</b> ¬∑ —Ä–µ–∂–∏–º: <u>{'FACT' if fact_mode else 'GENERAL'}</u> ¬∑ {time.strftime('%H:%M:%S')}"
    qline=f"<i>–í–æ–ø—Ä–æ—Å:</i> {html.escape(question)}"
    src=[ln.rstrip() for ln in raw.splitlines()]
    out=[]; blank=False
    for ln in src:
        if not ln.strip():
            if not blank: out.append("")
            blank=True; continue
        blank=False
        if re.match(r"^[-*‚Ä¢‚Äî]\s", ln) or re.match(r"^\d+[\).]\s", ln):
            ln="‚Ä¢ "+re.sub(r"^[-*‚Ä¢‚Äî]\s*","",ln)
        out.append(ln)
    body=html.escape("\n".join(out))
    body=_html_highlight(body)
    return f"{header}\n{SEP_THIN}\n{qline}\n{SEP_THIN}\n{body}"

def _gigachat_verify_param():
    mode=os.getenv("GIGACHAT_SSL_MODE","auto").lower().strip()
    verify=os.getenv("GIGACHAT_VERIFY_SSL","1")!="0"
    ca=os.getenv("GIGACHAT_CA_CERT","/app/ca/gigachat_ca.pem").strip()
    if mode=="insecure": return False
    if mode=="custom":
        if not os.path.isfile(ca):
            log.warning("GigaChat CA –Ω–µ –Ω–∞–π–¥–µ–Ω (%s)", ca)
            return verify
        return ca
    return verify

def _read_token_cache_file():
    if not GIGACHAT_TOKEN_CACHE_FILE.exists(): return None
    try: return json.loads(GIGACHAT_TOKEN_CACHE_FILE.read_text("utf-8"))
    except Exception: return None

def _write_token_cache_file(data:dict):
    try: _atomic_write(GIGACHAT_TOKEN_CACHE_FILE, json.dumps(data, ensure_ascii=False, indent=2))
    except Exception as e: log.warning("token cache write error: %s", e)

def _token_valid(tok:dict)->bool:
    if not tok: return False
    exp=tok.get("expires_epoch")
    if not exp and tok.get("obtained_at") and tok.get("expires_in"):
        exp=tok["obtained_at"]+int(tok["expires_in"])
    if not exp: return False
    return (exp-time.time())>120

async def get_gigachat_token(force=False)->str:
    if not GIGACHAT_ENABLED: raise RuntimeError("LLM_PROVIDER != gigachat")
    cid=GIGACHAT_CLIENT_ID; sec=GIGACHAT_CLIENT_SECRET
    if not cid or not sec: raise RuntimeError("–ü—É—Å—Ç—ã–µ CLIENT_ID/SECRET")
    global _GIGACHAT_TOKEN_MEM
    if not force and _token_valid(_GIGACHAT_TOKEN_MEM):
        return _GIGACHAT_TOKEN_MEM["access_token"]
    if not force:
        cache=_read_token_cache_file()
        if _token_valid(cache):
            _GIGACHAT_TOKEN_MEM=cache
            return cache["access_token"]
    headers={"RqUID":str(uuid.uuid4()),"Content-Type":"application/x-www-form-urlencoded","Accept":"application/json"}
    data={"scope":GIGACHAT_SCOPE}
    async with httpx.AsyncClient(verify=_gigachat_verify_param(), timeout=GIGACHAT_TIMEOUT_SECONDS, trust_env=True) as client:
        resp=await client.post(GIGACHAT_TOKEN_URL,data=data,headers=headers,auth=(cid,sec))
    if resp.status_code>=400:
        raise RuntimeError(f"OAuth {resp.status_code}: {resp.text}")
    js=resp.json(); obtained=int(time.time())
    exp_epoch=js.get("expires_at")
    if not exp_epoch and js.get("expires_in"):
        try: exp_epoch=obtained+int(js["expires_in"])
        except Exception: pass
    if not exp_epoch: exp_epoch=obtained+1800
    token_obj={"access_token":js.get("access_token"),"obtained_at":obtained,"expires_in":js.get("expires_in"),"expires_epoch":exp_epoch}
    if not token_obj["access_token"]: raise RuntimeError("–û—Ç–≤–µ—Ç –±–µ–∑ access_token")
    _GIGACHAT_TOKEN_MEM=token_obj; _write_token_cache_file(token_obj)
    return token_obj["access_token"]

FULL_DUMP_PATTERNS=["–≤–µ—Å—å –æ–±—ä–µ–º","–≤–µ—Å—å –æ–±—ä—ë–º","–≤—Å–µ –¥–∞–Ω–Ω—ã–µ","–ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫","–ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ—á–µ–Ω—å","full dump","–≤—Å–µ sku","–≤–µ—Å—å –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç","–¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã","–≤—Å–µ —Ç–æ–≤–∞—Ä—ã"]
PRODUCT_LIST_PATTERNS=["–∫–∞–∫–∏–µ —Ç–æ–≤–∞—Ä—ã","—Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤","–ø–µ—Ä–µ—á–µ–Ω—å —Ç–æ–≤–∞—Ä–æ–≤","–∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç","–∫–∞–∫–∏–µ —É –Ω–∞—Å —Ç–æ–≤–∞—Ä—ã","—á—Ç–æ –∑–∞ —Ç–æ–≤–∞—Ä—ã"]

def extract_skus_from_question(q:str)->List[int]:
    return [int(m.group()) for m in re.finditer(r"\b\d{3,}\b", q)]

def is_full_dump_question(q:str)->bool:
    ql=q.lower(); return any(p in ql for p in FULL_DUMP_PATTERNS)

def is_list_products_question(q:str)->bool:
    ql=q.lower(); return any(p in ql for p in PRODUCT_LIST_PATTERNS)

def _trim_facts(text:str)->str:
    if len(text)<=LLM_FACT_SOFT_LIMIT_CHARS: return text
    out=[]; total=0; limit=LLM_FACT_SOFT_LIMIT_CHARS-300
    for ln in text.splitlines():
        if total+len(ln)+1>limit:
            out.append("...(—É—Å–µ—á–µ–Ω–æ)"); break
        out.append(ln); total+=len(ln)+1
    return "\n".join(out)

def build_facts_block(question:str)->Tuple[str,str]:
    if not FACT_INDEX: return "NO_DATA_INDEX","empty"
    q=question.strip(); skus_in=extract_skus_from_question(q)
    sku_data=FACT_INDEX.get("sku",{}); inv=FACT_INDEX.get("inventory_overview",{})
    mode="general"
    if is_full_dump_question(q):
        mode="full_dump"
        lines=[f"snapshot_ts={FACT_INDEX['snapshot_ts']} TOTAL_SKU={inv.get('total_sku')}"]
        for sku, entry in list(sku_data.items())[:LLM_FULL_DETAIL_SKU]:
            lines.append(f"SKU {sku} '{entry['name']}' worst_cov={round(entry['worst_coverage'],3)} total_qty={entry['total_qty']} deficit_need={entry['deficit_need']}")
            for w in entry["warehouses"][:LLM_FULL_DETAIL_WAREHOUSES]:
                lines.append(f"  WH '{w['name']}' qty={w['qty']} norm={w['norm']} target={w['target']} need_norm={w['need']} cov={w['coverage']}")
        return _trim_facts("\n".join(lines)), mode
    if skus_in:
        mode="specific"
        lines=[f"snapshot_ts={FACT_INDEX['snapshot_ts']} TOTAL_SKU={inv.get('total_sku')}"]
        for sku in skus_in[:LLM_MAX_CONTEXT_SKU]:
            entry=sku_data.get(sku)
            if not entry:
                lines.append(f"SKU {sku}: NO_DATA"); continue
            lines.append(f"SKU {sku} '{entry['name']}' worst_cov={round(entry['worst_coverage'],3)} total_qty={entry['total_qty']} deficit_need={entry['deficit_need']}")
            for w in entry["warehouses"][:LLM_MAX_CONTEXT_WAREHOUSE]:
                lines.append(f"  WH '{w['name']}' qty={w['qty']} norm={w['norm']} target={w['target']} need_norm={w['need']} cov={w['coverage']}")
        return _trim_facts("\n".join(lines)), mode
    if is_list_products_question(q):
        mode="list"
        lines=[f"snapshot_ts={FACT_INDEX['snapshot_ts']} TOTAL_SKU={inv.get('total_sku')}", "SAMPLE_SKUS:"]
        for s in inv.get("sample_skus",[])[:LLM_INVENTORY_SAMPLE_SKU]:
            lines.append(f"  {s}")
        return _trim_facts("\n".join(lines)), mode
    lines=[f"snapshot_ts={FACT_INDEX['snapshot_ts']} TOTAL_SKU={inv.get('total_sku')}"]
    for td in FACT_INDEX.get("top_deficits",[])[:LLM_TOP_DEFICITS]:
        lines.append(f"TOP_DEFICIT SKU {td['sku']} '{td['name']}' cov={td['coverage']} need_def={td['deficit_need']}")
    return _trim_facts("\n".join(lines)), mode

def build_messages_fact(question:str)->Tuple[List[Dict[str,str]], str]:
    facts, mode=build_facts_block(question)
    if facts=="NO_DATA_INDEX":
        return [
            {"role":"system","content":"–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ FACTS. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'."},
            {"role":"user","content":question}
        ], mode
    system="–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –æ—Å—Ç–∞—Ç–∫–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –¥–∞–Ω–Ω—ã–µ –∏–∑ FACTS; –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π."
    return [
        {"role":"system","content":system},
        {"role":"user","content":f"–í–æ–ø—Ä–æ—Å:\n{question}\n\nFACTS:\n{facts}"}
    ], mode

GENERAL_WORK_KEYWORDS=["sku","—Å–∫–ª–∞–¥","—Å–∫–ª–∞–¥—ã","–¥–µ—Ñ–∏—Ü–∏—Ç","–Ω–æ—Ä–º","target","–ø–æ–∫—Ä—ã—Ç","–æ—Å—Ç–∞—Ç","—Ç–æ–≤–∞—Ä","ozon","–æ–∑–æ–Ω","–∫–ª–∞—Å—Ç–µ—Ä"]
def looks_like_work_question(q:str)->bool:
    ql=q.lower()
    if re.search(r"\b\d{5,}\b", ql): return True
    return any(k in ql for k in GENERAL_WORK_KEYWORDS)

def add_general_history(chat_id:int, role:str, content:str):
    arr=GENERAL_HISTORY.setdefault(chat_id,[])
    arr.append({"role":role,"content":content})
    if len(arr)>GENERAL_HISTORY_MAX:
        del arr[0:len(arr)-GENERAL_HISTORY_MAX]

def build_general_messages(chat_id:int, question:str)->List[Dict[str,str]]:
    history=GENERAL_HISTORY.get(chat_id,[])
    sys="–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –æ—Å—Ç–∞—Ç–∫–∏/—Å–∫–ª–∞–¥—ã ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ /ai."
    msgs=[{"role":"system","content":sys}]
    for msg in history[-(GENERAL_HISTORY_MAX-1):]:
        msgs.append(msg)
    msgs.append({"role":"user","content":question})
    if looks_like_work_question(question):
        msgs.append({"role":"system","content":"–†–∞–±–æ—á–∏–π –≤–æ–ø—Ä–æ—Å ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ /ai."})
    return msgs

async def llm_fact_answer(question:str)->Tuple[str,str]:
    if not GIGACHAT_ENABLED: return "LLM –æ—Ç–∫–ª—é—á—ë–Ω.","off"
    q=question.strip()
    if not q: return "–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å.","empty"
    global _LAST_AI_CALL
    now=time.time()
    if now-_LAST_AI_CALL<AI_MIN_INTERVAL_SECONDS:
        return f"–°–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ. –ü–æ–¥–æ–∂–¥–∏—Ç–µ {AI_MIN_INTERVAL_SECONDS-int(now-_LAST_AI_CALL)} —Å–µ–∫.","rate"
    await ensure_fact_index()
    messages, mode=build_messages_fact(q)
    key=hashlib.sha1(f"{mode}|{FACT_INDEX.get('snapshot_ts')}|{q.lower()}".encode()).hexdigest()
    if ANSWER_CACHE.get(key):
        return "(–∏–∑ –∫—ç—à–∞)\n"+ANSWER_CACHE[key], mode
    _LAST_AI_CALL=now
    try:
        token=await get_gigachat_token()
    except Exception as e:
        return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω: {e}","auth"
    payload={"model":GIGACHAT_MODEL,"messages":messages,"temperature":min(0.2,GIGACHAT_TEMPERATURE),"max_tokens":GIGACHAT_MAX_TOKENS}
    try:
        async with httpx.AsyncClient(verify=_gigachat_verify_param(),timeout=GIGACHAT_TIMEOUT_SECONDS,trust_env=True) as client:
            r=await client.post(GIGACHAT_API_URL,json=payload,headers={"Authorization":f"Bearer {token}","Content-Type":"application/json"})
            if r.status_code==401:
                _GIGACHAT_TOKEN_MEM={}
                token=await get_gigachat_token(force=True)
                r=await client.post(GIGACHAT_API_URL,json=payload,headers={"Authorization":f"Bearer {token}","Content-Type":"application/json"})
            if r.status_code>=400:
                return f"GigaChat HTTP {r.status_code}: {r.text[:250]}","http"
            data=r.json()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}","net"
    ch=data.get("choices")
    if not ch: return f"–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç: {data}","empty"
    text=(ch[0].get("message",{}).get("content") or "").strip()
    ANSWER_CACHE[key]=text
    return text, mode

async def llm_general_answer(chat_id:int, question:str)->Tuple[str,str]:
    if not GIGACHAT_ENABLED: return "LLM –æ—Ç–∫–ª—é—á—ë–Ω.","off"
    q=question.strip()
    if not q: return "–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å.","empty"
    global _LAST_AI_CALL
    now=time.time()
    if now-_LAST_AI_CALL<AI_MIN_INTERVAL_SECONDS:
        return f"–°–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ. –ü–æ–¥–æ–∂–¥–∏—Ç–µ {AI_MIN_INTERVAL_SECONDS-int(now-_LAST_AI_CALL)} —Å–µ–∫.","rate"
    _LAST_AI_CALL=now
    messages=build_general_messages(chat_id,q)
    try:
        token=await get_gigachat_token()
    except Exception as e:
        return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω: {e}","auth"
    payload={"model":GIGACHAT_MODEL,"messages":messages,"temperature":LLM_GENERAL_TEMPERATURE,"max_tokens":GIGACHAT_MAX_TOKENS}
    try:
        async with httpx.AsyncClient(verify=_gigachat_verify_param(),timeout=GIGACHAT_TIMEOUT_SECONDS,trust_env=True) as client:
            r=await client.post(GIGACHAT_API_URL,json=payload,headers={"Authorization":f"Bearer {token}","Content-Type":"application/json"})
            if r.status_code>=400:
                return f"GigaChat HTTP {r.status_code}: {r.text[:250]}","http"
            data=r.json()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}","net"
    ch=data.get("choices")
    if not ch: return f"–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç: {data}","empty"
    text=(ch[0].get("message",{}).get("content") or "").strip()
    add_general_history(chat_id,"user",q); add_general_history(chat_id,"assistant",text)
    return text,"general"

# ==== Messaging helpers ====
async def send_safe_message(chat_id:int,text:str,**kwargs):
    if not text: text="\u200b"
    try: return await bot.send_message(chat_id,text,**kwargs)
    except TelegramRetryAfter as e:
        await asyncio.sleep(e.retry_after)
        return await bot.send_message(chat_id,text,**kwargs)
    except Exception as e:
        log.warning("send fail: %s", e)

async def send_long(chat_id:int,text:str,kb:Optional[InlineKeyboardMarkup]=None):
    max_len=3900
    parts=[]; buf=[]; ln=0
    for line in (text or "").split("\n"):
        L=len(line)+1
        if buf and ln+L>max_len:
            parts.append("\n".join(buf)); buf=[line]; ln=L
        else:
            buf.append(line); ln+=L
    if buf: parts.append("\n".join(buf))
    if not parts: parts=["\u200b"]
    for i,chunk in enumerate(parts):
        await send_safe_message(chat_id,chunk.rstrip() or "\u200B",
                                parse_mode="HTML",
                                disable_web_page_preview=True,
                                reply_markup=kb if (kb and i==len(parts)-1) else None)
        await asyncio.sleep(0.02)

# ==== Tasks logic ====
# –°—Ç–∞–¥–∏–∏ (—Ä–∞—Å—à–∏—Ä–µ–Ω–æ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã supply_watch/Ozon)
DRAFT_STATUSES={"DRAFT","NEW","INITIAL","CALCULATION_STATUS_PENDING"}
WAIT_STATUSES={"WAIT","WAITING","PENDING","IN_PROGRESS","ACTIVE","QUEUED",
               "CALCULATION_STATUS_SUCCESS","SUPPLY_ORDER_FETCH","POLL_SUPPLY"}
SLOT_STATUSES={"BOOKED","RESERVED","SCHEDULED","WINDOW_SET","SLOT_SET","SLOT_BOOKED"}
CREATING_STATUSES={"CREATING","CREATING_SUPPLY","SUPPLY_CREATING","SUPPLY_CREATE","CREATING_DRAFT"}
APPLICATION_FILL_STATUSES={"ORDER_DATA_FILLING"}  # —Å—Ç–∞–¥–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞—è–≤–∫–∏
DONE_STATUSES={"DONE","SUCCESS","FINISHED","COMPLETED","SUPPLY_CREATED"}
CREATED_STATUSES={"CREATED","UI_STATUS_CREATED","–°–û–ó–î–ê–ù–û"}
ERROR_STATUSES={"ERROR","FAILED"}
CANCEL_STATUSES={"CANCELLED","CANCELED"}

DEFAULT_STAGE_EMOJI_RU={
    "–ß–µ—Ä–Ω–æ–≤–∏–∫":"üìù","–û–∂–∏–¥–∞–Ω–∏–µ":"‚è≥","–°–ª–æ—Ç":"üïò","–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏":"üìù",
    "–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞—è–≤–∫–∏":"üõ†","–ì–æ—Ç–æ–≤–æ":"‚úÖ","–û—à–∏–±–∫–∞":"‚ùå","–û—Ç–º–µ–Ω–µ–Ω–æ":"üö´","–û–∂–∏–¥–∞–Ω–∏–µ supply":"üîÑ"
}

def resolve_abf_stage_emoji_map()->Dict[str,str]:
    try:
        if AUTOBOOK_ENABLED and 'abf' in globals() and abf:
            for name in dir(abf):
                obj=getattr(abf,name)
                if isinstance(obj,dict):
                    keys=set(DEFAULT_STAGE_EMOJI_RU.keys())
                    if keys.issubset(set(obj.keys())):
                        return {str(k):str(v) for k,v in obj.items()}
    except Exception:
        pass
    return DEFAULT_STAGE_EMOJI_RU

# –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ä—Ç–∞ —ç–º–æ–¥–∑–∏ —Å—Ç–∞–¥–∏–π
STAGE_EMOJI_RU = resolve_abf_stage_emoji_map()

def classify_task_stage(task:Dict[str,Any])->Tuple[str,str]:
    """
    –í–ê–ñ–ù–û: —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ/—Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–¥–∏–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Ä–∞–Ω—å—à–µ –æ—à–∏–±–æ–∫, —á—Ç–æ–±—ã –Ω–µ –º–µ—Ç–∏—Ç—å –≥–æ—Ç–æ–≤—ã–µ –∑–∞—è–≤–∫–∏ –∫–∞–∫ ¬´–û—à–∏–±–∫–∞¬ª.
    """
    status=(task.get("status") or task.get("state") or "").upper()
    creating=bool(task.get("creating"))
    desired_from_iso=task.get("desired_from_iso") or ""
    last_error=(task.get("last_error") or "").strip()

    # –û—Ç–º–µ–Ω–µ–Ω–æ
    if status in CANCEL_STATUSES:
        return (STAGE_EMOJI_RU.get("–û—Ç–º–µ–Ω–µ–Ω–æ","üö´"),"–û—Ç–º–µ–Ω–µ–Ω–æ")
    # –ì–æ—Ç–æ–≤–æ
    if status in DONE_STATUSES:
        return (STAGE_EMOJI_RU.get("–ì–æ—Ç–æ–≤–æ","‚úÖ"),"–ì–æ—Ç–æ–≤–æ")
    # –°–æ–∑–¥–∞–Ω–æ (–≤–∫–ª—é—á–∞—è UI-–º–µ—Ç–∫–∏ —Å–æ–∑–¥–∞–Ω–æ)
    if status in CREATED_STATUSES:
        return (STAGE_EMOJI_RU.get("–ì–æ—Ç–æ–≤–æ","‚úÖ"),"–°–æ–∑–¥–∞–Ω–æ")
    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏ —Å—á–∏—Ç–∞–µ–º ¬´—Å–æ–∑–¥–∞–Ω–æ¬ª —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    if status in APPLICATION_FILL_STATUSES or status=="CREATING_DRAFT" or creating:
        # –í —Å—Ç–∞–¥–∏–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ ¬´–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏¬ª, –Ω–æ –Ω–µ ¬´–û—à–∏–±–∫–∞¬ª
        return (STAGE_EMOJI_RU.get("–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏","üìù"),"–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏")
    # –°–ª–æ—Ç
    if status in SLOT_STATUSES:
        return (STAGE_EMOJI_RU.get("–°–ª–æ—Ç","üïò"),"–°–ª–æ—Ç")
    # –û–∂–∏–¥–∞–Ω–∏–µ supply
    if "SUPPLY_ORDER_FETCH" in status or "POLL_SUPPLY" in status:
        return (STAGE_EMOJI_RU.get("–û–∂–∏–¥–∞–Ω–∏–µ supply","üîÑ"),"–û–∂–∏–¥–∞–Ω–∏–µ supply")
    # –ß–µ—Ä–Ω–æ–≤–∏–∫–∏/–æ–∂–∏–¥–∞–Ω–∏—è
    if status in DRAFT_STATUSES:
        if desired_from_iso and status=="WAIT_WINDOW":
            return (STAGE_EMOJI_RU.get("–û–∂–∏–¥–∞–Ω–∏–µ","‚è≥"),"–û–∂–∏–¥–∞–Ω–∏–µ")
        return (STAGE_EMOJI_RU.get("–ß–µ—Ä–Ω–æ–≤–∏–∫","üìù"),"–ß–µ—Ä–Ω–æ–≤–∏–∫")
    if status in WAIT_STATUSES or status.startswith("WAIT_"):
        return (STAGE_EMOJI_RU.get("–û–∂–∏–¥–∞–Ω–∏–µ","‚è≥"),"–û–∂–∏–¥–∞–Ω–∏–µ")

    # –û—à–∏–±–∫–∞ ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Å—Ç–∞–¥–∏–π
    if status in ERROR_STATUSES or last_error:
        return (STAGE_EMOJI_RU.get("–û—à–∏–±–∫–∞","‚ùå"),"–û—à–∏–±–∫–∞")

    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —á–µ—Ä–Ω–æ–≤–∏–∫
    return (STAGE_EMOJI_RU.get("–ß–µ—Ä–Ω–æ–≤–∏–∫","üìù"),"–ß–µ—Ä–Ω–æ–≤–∏–∫")

def _first_time_or_dash(task:Dict[str,Any])->str:
    ts=task.get("timeslot") or ""
    if ts: return ts
    f=task.get("desired_from_iso"); t=task.get("desired_to_iso")
    try:
        if f and t and "T" in f and "T" in t:
            return f"{f.split('T')[1][:5]}-{t.split('T')[1][:5]}"
    except Exception: pass
    return "-"

def _sum_qty(task:Dict[str,Any])->int:
    total=0
    sl=task.get("sku_list")
    if isinstance(sl,list):
        for it in sl:
            try: total+=int(it.get("total_qty") or it.get("qty") or 0)
            except Exception: pass
        return total
    try: return int(task.get("qty") or 0)
    except Exception: return 0

def _first_sku(task:Dict[str,Any])->Optional[int]:
    sl=task.get("sku_list")
    if isinstance(sl,list) and sl:
        try: return int(sl[0].get("sku") or 0)
        except Exception: return None
    try: return int(task.get("sku") or 0)
    except Exception: return None

def _task_warehouse_name(task:Dict[str,Any])->str:
    for key in ("warehouse_name","chosen_warehouse_name","drop_off_name"):
        if task.get(key): return str(task[key])
    sl=task.get("sku_list")
    if isinstance(sl,list) and sl:
        w=sl[0].get("warehouse_name")
        if w: return str(w)
    for key in ("chosen_warehouse_id","drop_off_id","warehouse_id"):
        if task.get(key): return f"id:{task[key]}"
    return "-"

def normalize_tasks_result(res:Any)->List[Dict[str,Any]]:
    if not res: return []
    if isinstance(res, dict):
        out=[]
        for key in ("tasks","items","result"):
            v=res.get(key)
            if isinstance(v,list) and (not v or isinstance(v[0],dict)):
                out.extend([t for t in v if isinstance(t,dict)])
        if out: return out
        for v in res.values():
            if isinstance(v,list) and v and isinstance(v[0],dict):
                out.extend(v)
        if out: return out
        if "id" in res: return [res]
        return []
    if isinstance(res,list) and res and isinstance(res[0],dict):
        return res
    return []

def fallback_tasks_from_events()->List[Dict[str,Any]]:
    arr=SUPPLY_EVENTS.get("*") or []
    out=[]; seen=set()
    for e in reversed(arr):
        payload=e.get("payload") or {}
        tid=payload.get("id") or payload.get("task_id")
        if not tid:
            m=re.search(r"([a-f0-9]{8}-[a-f0-9-]{13,})",(e.get("text") or ""),re.I)
            if m: tid=m.group(1)
        if not tid or tid in seen: continue
        seen.add(tid)
        t={
            "id":tid,"status":(e.get("status") or "DRAFT").upper(),"date":payload.get("date") or "",
            "timeslot":payload.get("timeslot") or "","creating":payload.get("creating") or False,
            "desired_from_iso":payload.get("desired_from_iso") or "","desired_to_iso":payload.get("desired_to_iso") or "",
            "last_error":payload.get("last_error") or "","sku_list":payload.get("sku_list") or [],
            "warehouse_name":payload.get("warehouse_name") or payload.get("drop_off_name") or "",
            "crossdock_id":payload.get("crossdock_id") or "",
            "crossdock_name":payload.get("crossdock_name") or "",
        }
        if not t["sku_list"]:
            qty=payload.get("qty") or 0
            sku=payload.get("sku")
            t["sku_list"]=[{"sku":sku,"total_qty":qty,"warehouse_name":t["warehouse_name"]}]
        out.append(t)
    out.reverse()
    clean=[t for t in out if not (_sum_qty(t)==0 and _task_warehouse_name(t)=="-" and not _first_sku(t))]
    return clean

async def fetch_tasks_global()->List[Dict[str,Any]]:
    tasks=[]
    try:
        import supply_watch as swm
        for name in ("list_tasks","list_all_tasks","get_tasks","dump_tasks"):
            fn=getattr(swm,name,None)
            if not fn: continue
            res=fn()
            if inspect.isawaitable(res): res=await res
            tasks=normalize_tasks_result(res)
            if tasks: break
    except Exception: pass
    if not tasks:
        try:
            import flows.autobook_flow as abfm
            for name in ("list_tasks","get_tasks"):
                fn=getattr(abfm,name,None)
                if not fn: continue
                res=fn()
                if inspect.isawaitable(res): res=await res
                tasks=normalize_tasks_result(res)
                if tasks: break
        except Exception: pass
    if not tasks:
        try:
            import supply_integration as sim
            for name in ("list_tasks","get_tasks"):
                fn=getattr(sim,name,None)
                if not fn: continue
                res=fn()
                if inspect.isawaitable(res): res=await res
                tasks=normalize_tasks_result(res)
                if tasks: break
        except Exception: pass
    if not tasks:
        tasks=fallback_tasks_from_events()
    return tasks

def _human_window(timeslot:str="", from_iso:str="", to_iso:str="")->str:
    ts_raw=(timeslot or "").strip()
    iso_pat=r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(?:Z|[+\-]\d{2}:\d{2})'
    iso=re.findall(iso_pat, ts_raw)
    if len(iso)>=2:
        from_iso=iso[0]; to_iso=iso[1]
    def _p(v):
        if not v: return None
        v=v.replace("Z","+00:00")
        try: return datetime.datetime.fromisoformat(v)
        except Exception: return None
    df=_p(from_iso); dt=_p(to_iso)
    if df and dt:
        mons=["—è–Ω–≤","—Ñ–µ–≤","–º–∞—Ä","–∞–ø—Ä","–º–∞–π","–∏—é–Ω","–∏—é–ª","–∞–≤–≥","—Å–µ–Ω","–æ–∫—Ç","–Ω–æ—è","–¥–µ–∫"]
        wds=["–ü–Ω","–í—Ç","–°—Ä","–ß—Ç","–ü—Ç","–°–±","–í—Å"]
        tz=df.strftime("%z"); tz_fmt=f"(UTC{tz[:3]}:{tz[3:]})" if tz else ""
        if df.date()==dt.date():
            return f"{df.day} {mons[df.month-1]} ({wds[df.weekday()]}) {df:%H:%M}‚Äì{dt:%H:%M} {tz_fmt}"
        return f"{df.day} {mons[df.month-1]} ({wds[df.weekday()]}) {df:%H:%M} ‚Üí {dt.day} {mons[dt.month-1]} ({wds[dt.weekday()]}) {dt:%H:%M} {tz_fmt}"
    # Fallback: HH:MM-HH:MM
    if ts_raw and re.match(r'^\d{2}:\d{2}-\d{2}:\d{2}$', ts_raw):
        return ts_raw.replace('-', '‚Äì')
    return ts_raw or from_iso or to_iso or "-"

# ==== Application status helpers ====
def _application_status_text(status:str)->str:
    s=status.upper().strip()
    if s in APPLICATION_FILL_STATUSES or s in CREATED_STATUSES:
        return "‚úÖ –°–æ–∑–¥–∞–Ω–æ"
    if s in DONE_STATUSES:
        return "‚úÖ –ì–æ—Ç–æ–≤–æ"
    if s in CREATING_STATUSES:
        return "üõ† –°–æ–∑–¥–∞–Ω–∏–µ"
    if s in CANCEL_STATUSES:
        return "üö´ –û—Ç–º–µ–Ω–µ–Ω–æ"
    if s in ERROR_STATUSES:
        return "‚ùå –û—à–∏–±–∫–∞"
    return "‚Äî"

# ==== Lists renderers (Tasks/Applications) ====
def build_tasks_list_text(tasks:List[Dict[str,Any]], chat_id:int)->str:
    """
    Build tasks list with full product names (resolved from SKU) and improved formatting.
    Shows: stage emoji + stage + date + time window; product name + SKU + qty + ID; warehouse + crossdock.
    """
    if not tasks:
        return build_html(["¬ß¬ßB¬ß¬ßüìã –ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ (0)¬ß¬ßEB¬ß¬ß",SEP_THIN,"–°–µ–π—á–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö (–Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö) –∑–∞–¥–∞—á."])
    lines=[f"¬ß¬ßB¬ß¬ßüìã –ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ ({len(tasks)})¬ß¬ßEB¬ß¬ß",SEP_THIN]
    for i,t in enumerate(tasks,1):
        em,stage=classify_task_stage(t)
        qty=_sum_qty(t)
        date=t.get("date") or (t.get("desired_from_iso","")[:10] if t.get("desired_from_iso") else "-")
        slot=_human_window(t.get("timeslot") or "", t.get("desired_from_iso") or "", t.get("desired_to_iso") or "")
        sku=_first_sku(t)
        tid=t.get("id") or "-"
        wh=_task_warehouse_name(t)
        cd=_resolve_crossdock_name_warehouses(t, chat_id)
        # Resolve product name
        if sku and sku > 0:
            product_name = get_sku_name_local(sku)
            # If name is just "SKU {n}", try lazy fetch
            if product_name.startswith("SKU "):
                product_name = get_or_fetch_sku_name_lazy(sku)
            sku_display = str(sku)
        else:
            product_name = "-"
            sku_display = "-"
        # Format: stage + date + time on first line; product + SKU + qty + ID on second; warehouse + crossdock on third
        lines.append(f"{i}) {em} {stage} | {date} {slot}")
        lines.append(f"   ¬ß¬ßB¬ß¬ß{html.escape(product_name)}¬ß¬ßEB¬ß¬ß (SKU {sku_display}) | {qty} —à—Ç | ID {tid}")
        lines.append(f"   –°–∫–ª–∞–¥ –ø–æ—Å—Ç–∞–≤–∫–∏: ¬ß¬ßB¬ß¬ß{html.escape(wh)}¬ß¬ßEB¬ß¬ß | –ö—Ä–æ—Å—Å–¥–æ–∫: ¬ß¬ßB¬ß¬ß{html.escape(cd)}¬ß¬ßEB¬ß¬ß")
    return build_html(lines)

def _last_created_tasks(limit:int=3)->List[Dict[str,Any]]:
    """
    Scan SUPPLY_EVENTS["*"] in reverse chronological order and collect unique applications.
    Treats as "created": CREATED, DONE, SUCCESS, FINISHED, COMPLETED, SUPPLY_CREATED, 
    ORDER_DATA_FILLING, and textual mentions like "—Å–æ–∑–¥–∞–Ω".
    """
    arr=SUPPLY_EVENTS.get("*") or []
    created=[]
    seen=set()
    for e in reversed(arr):
        payload=e.get("payload") or {}
        tid=payload.get("id") or payload.get("task_id") or ""
        if not tid or tid in seen:
            continue
        txt=(e.get("text") or "").lower()
        st=(e.get("status") or "").lower()
        # Treat as created: explicit states + ORDER_DATA_FILLING + textual mentions
        if "—Å–æ–∑–¥–∞–Ω" in txt or st in ("created","done","success","finished","completed","supply_created","supply created","order_data_filling"):
            seen.add(tid)
            created.append(payload)
            if len(created)>=limit:
                break
    return created

def build_last_created_tasks_text(limit:int=3)->str:
    tasks=_last_created_tasks(limit)
    if not tasks:
        return build_html(["<b>–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ (0)</b>", "–ù–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫.", SEP_THIN])
    lines=[f"<b>–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ ({len(tasks)})</b>", SEP_THIN]
    for i,p in enumerate(tasks,1):
        tid=p.get("id") or p.get("task_id") or "-"
        sku_list=p.get("sku_list") or []
        qty=sum(int(it.get("qty") or it.get("total_qty") or 0) for it in sku_list)
        warehouse=p.get("warehouse_name") or p.get("drop_off_name") or "-"
        cd = p.get("crossdock_name") or p.get("crossdock_id") or ""
        slot=_human_window(p.get("timeslot") or "", p.get("desired_from_iso") or "", p.get("desired_to_iso") or "")
        lines.append(f"{i}. ID {tid} | {qty} —à—Ç | –°–ª–æ—Ç: {slot}")
        lines.append(f"   –°—Ç–∞—Ç—É—Å: ‚úÖ –°–æ–∑–¥–∞–Ω–æ")
        lines.append(f"   –°–∫–ª–∞–¥ –ø–æ—Å—Ç–∞–≤–∫–∏: ¬ß¬ßB¬ß¬ß{html.escape(warehouse)}¬ß¬ßEB¬ß¬ß | –ö—Ä–æ—Å—Å–¥–æ–∫: ¬ß¬ßB¬ß¬ß{html.escape(cd)}¬ß¬ßEB¬ß¬ß")
    lines.append(SEP_THIN)
    return build_html(lines)

# ==== Crossdocks ENV parsers (–¥–ª—è –∏–º—ë–Ω –∫—Ä–æ—Å—Å–¥–æ–∫–æ–≤ –≤ —Å–ø–∏—Å–∫–µ –∑–∞–¥–∞—á) ====
CROSSDOCKS_MAP = {}

def _load_crossdocks_warehouses_env() -> None:
    raw = (os.environ.get("CROSSDOCK_WAREHOUSES") or os.environ.get("CROSSDOCKS_WAREHOUSES") or "").strip()
    if not raw:
        return
    # strip surrounding quotes if present
    if (raw.startswith('"') and raw.endswith('"')) or (raw.startswith("'") and raw.endswith("'")):
        raw = raw[1:-1]
    # normalize: replace commas with newlines
    text = raw.replace(",", "\n")
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    m = {}
    for item in lines:
        tokens = item.split()
        if not tokens:
            continue
        id_token = tokens[-1]
        name = " ".join(tokens[:-1]).strip()
        id_digits = "".join(ch for ch in id_token if ch.isdigit())
        if id_digits and name:
            m[id_digits] = name
    if m:
        globals()["CROSSDOCKS_MAP"] = m

def _load_crossdocks_env() -> None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ä—Ç—É –∫—Ä–æ—Å—Å–¥–æ–∫–æ–≤ –∏–∑ ENV:
    - CROSSDOCKS_JSON: JSON-—Å—Ç—Ä–æ–∫–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä [{"id":"102000..","name":"–•–ê–ë–ê–†–û–í–°–ö_2_–†–§–¶_–ö–†–û–°–°–î–û–ö–ò–ù–ì"}, ...]
    - CROSSDOCKS: CSV-—Å—Ç—Ä–æ–∫–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º, —Ñ–æ—Ä–º–∞—Ç "id;name" (–æ–¥–Ω–∞ –ø–∞—Ä–∞ –Ω–∞ —Å—Ç—Ä–æ–∫—É)
    """
    import json as _json
    raw_json = os.environ.get("CROSSDOCKS_JSON", "").strip()
    raw_csv = os.environ.get("CROSSDOCKS", "").strip()
    m = {}
    # JSON —Å–Ω–∞—á–∞–ª–∞
    if raw_json:
        try:
            arr = _json.loads(raw_json)
            if isinstance(arr, list):
                for it in arr:
                    cid = str((it.get("id") or it.get("code") or "")).strip()
                    name = str((it.get("name") or it.get("title") or "")).strip()
                    if cid and name:
                        m[cid] = name
        except Exception:
            pass
    # CSV "id;name"
    if raw_csv and not m:
        for line in raw_csv.splitlines():
            line=line.strip()
            if not line or line.startswith("#"): continue
            parts=line.split(";")
            if len(parts)>=2:
                cid=parts[0].strip()
                name=";".join(parts[1:]).strip()
                if cid and name:
                    m[cid] = name
    if m:
        globals()["CROSSDOCKS_MAP"] = m

def _resolve_crossdock_name_warehouses(t:dict, chat_id:int) -> str:
    """
    –ò–º—è –∫—Ä–æ—Å—Å–¥–æ–∫–∞ (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –∏–∑ ENV-–∫–∞—Ä—Ç).
    –ü–æ—Ä—è–¥–æ–∫:
      1) crossdock_name
      2) drop_off_name
      3) –ø–æ crossdock_id/drop_off_id –∏–∑ CROSSDOCKS_MAP (CROSSDOCK_WAREHOUSES / CROSSDOCKS / CROSSDOCKS_JSON)
      4) '‚Äî'
    """
    name = (t.get("crossdock_name") or "").strip()
    if name:
        return name
    dname = (t.get("drop_off_name") or "").strip()
    cid = str(t.get("crossdock_id") or "").strip()
    did = str(t.get("drop_off_id") or "").strip()
    # –ì–∞—Ä–∞–Ω—Ç–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ä—Ç—ã
    try:
        if not globals().get("CROSSDOCKS_MAP"):
            _load_crossdocks_warehouses_env()
            _load_crossdocks_env()
    except Exception:
        pass
    mp = globals().get("CROSSDOCKS_MAP") or {}
    def norm(v: str) -> str:
        return "".join(ch for ch in v if ch.isdigit())
    if dname:
        return dname
    cidn = norm(cid) if cid else ""
    didn = norm(did) if did else ""
    if cidn and cidn in mp:
        return mp[cidn]
    if didn and didn in mp:
        return mp[didn]
    return dname or "‚Äî"

def build_task_detail_text(t:Dict[str,Any], chat_id:int)->str:
    em,stage=classify_task_stage(t); qty=_sum_qty(t)
    date=t.get("date") or (t.get("desired_from_iso","")[:10] if t.get("desired_from_iso") else "-")
    slot=_human_window(t.get("timeslot") or "", t.get("desired_from_iso") or "", t.get("desired_to_iso") or "")
    tid=t.get("id") or "-"; wh=_task_warehouse_name(t)
    cd = _resolve_crossdock_name_warehouses(t, chat_id)
    lines=["¬ß¬ßB¬ß¬ß–î–µ—Ç–∞–ª–∏ –∑–∞—è–≤–∫–∏¬ß¬ßEB¬ß¬ß",
           f"ID: {tid}",
           f"–°—Ç–∞–¥–∏—è: {em} {stage}",
           f"–î–∞—Ç–∞: {date} | –û–∫–Ω–æ: {slot}",
           f"–ö—Ä–æ—Å—Å–¥–æ–∫: {html.escape(cd or '‚Äî')}",
           f"–°–∫–ª–∞–¥ –ø–æ—Å—Ç–∞–≤–∫–∏: {html.escape(wh)}",
           f"–ò—Ç–æ–≥–æ: {qty} —à—Ç",
           ""]
    sl=t.get("sku_list")
    if isinstance(sl,list) and sl:
        lines.append("–ü–æ–∑–∏—Ü–∏–∏:")
        for i,it in enumerate(sl,1):
            sku=it.get("sku"); q=it.get("total_qty") or it.get("qty") or 0
            # Validate and convert SKU
            try:
                sku_int = int(sku) if sku else 0
            except (ValueError, TypeError):
                sku_int = 0
            
            if sku_int > 0:
                sname=get_sku_name_local(sku_int)
                # If name is just "SKU {n}", try lazy fetch
                if sname.startswith("SKU "):
                    sname = get_or_fetch_sku_name_lazy(sku_int)
                sku_display = str(sku_int)
            else:
                sname = "-"
                sku_display = "-"
            wname=it.get("warehouse_name") or "-"
            lines.append(f"{i}. ¬ß¬ßB¬ß¬ß{html.escape(sname)}¬ß¬ßEB¬ß¬ß (SKU {sku_display}) ‚Äî {q} —à—Ç | {html.escape(wname)}")
        lines.append("")
    if t.get("last_error"):
        lines.append(f"–û—à–∏–±–∫–∞: {html.escape(t['last_error'])}")
    return build_html(lines)

# ==== –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á (single/all) ====
async def _try_delete_task_in_module(mod, tid:str) -> bool:
    if not mod: return False
    fn_candidates = [
        ("cancel_task", (tid,)),
        ("cancel_supply", (tid,)),
        ("delete_task", (tid,)),
        ("remove_task", (tid,)),
        ("drop_task", (tid,)),
        ("purge_task", (tid,)),
        ("purge_tasks", ([tid],)),
    ]
    for fn_name, args in fn_candidates:
        fn = getattr(mod, fn_name, None)
        if not fn:
            continue
        try:
            res = fn(*args)
            if inspect.isawaitable(res):
                await res
            return True
        except Exception as e:
            log.debug("delete %s in %s failed: %s", tid, getattr(mod, "__name__", mod), e)
            continue
    return False

async def delete_task_by_id(tid:str) -> bool:
    # –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –≤ supply_watch, –ø–æ—Ç–æ–º –≤ –≤–Ω–µ—à–Ω–µ–º –º–∞—Å—Ç–µ—Ä–µ, –ø–æ—Ç–æ–º –≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
    for mod in (sw, abf if AUTOBOOK_ENABLED else None, si):
        if await _try_delete_task_in_module(mod, tid):
            return True
    # –§–æ–ª–±—ç–∫: –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ purge_tasks, –µ—Å–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ –≥–ª–æ–±–∞–ª—å–Ω—ã–π
    try:
        if purge_tasks:
            res = purge_tasks([tid])
            if inspect.isawaitable(res):
                await res
            return True
    except Exception:
        pass
    return False

def _remove_task_from_caches(chat_id:int, tid:str):
    """
    Remove task from caches. Preserves application events (created/done states) 
    to keep last 3 created applications visible.
    """
    # –£–¥–∞–ª—è–µ–º –∏–∑ TASKS_CACHE
    lst = TASKS_CACHE.get(chat_id) or []
    TASKS_CACHE[chat_id] = [t for t in lst if str(t.get("id") or "") != str(tid)]
    # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–±—ã—Ç–∏—è –∑–∞–¥–∞—á (–Ω–µ –∑–∞—è–≤–æ–∫) –∏–∑ SUPPLY_EVENTS
    try:
        for key in list(SUPPLY_EVENTS.keys()):
            events = SUPPLY_EVENTS.get(key) or []
            filtered = []
            for e in events:
                payload = e.get("payload") or {}
                event_tid = str(payload.get("id") or payload.get("task_id") or "")
                if event_tid != str(tid):
                    # –ù–µ —ç—Ç–æ—Ç task - —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                    filtered.append(e)
                else:
                    # –≠—Ç–æ —Å–æ–±—ã—Ç–∏–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ task - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞—è–≤–∫–∞ –ª–∏ —ç—Ç–æ
                    text = (e.get("text") or "").lower()
                    status = (e.get("status") or "").lower()
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏—è –æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–∞—è–≤–∫–∞—Ö
                    if "—Å–æ–∑–¥–∞–Ω" in text or status in ("—Å–æ–∑–¥–∞–Ω–æ","created","done","success","finished","completed","supply_created","order_data_filling"):
                        filtered.append(e)
                    # –ò–Ω–∞—á–µ —É–¥–∞–ª—è–µ–º (—ç—Ç–æ —Å–æ–±—ã—Ç–∏–µ –æ–±—ã—á–Ω–æ–π –∑–∞–¥–∞—á–∏)
            SUPPLY_EVENTS[key] = filtered
        _persist_supply_events()
    except Exception as e:
        log.warning("SUPPLY_EVENTS purge for %s failed: %s", tid, e)

async def delete_all_tasks_for_chat(chat_id:int) -> int:
    """
    Delete all tasks for a chat. Applications data (SUPPLY_EVENTS, APPS_CACHE, NOTIFIED_CREATED) 
    is preserved so the last 3 created applications remain visible.
    """
    lst = TASKS_CACHE.get(chat_id) or []
    count = 0
    # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ purge_all_tasks ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º
    try:
        if purge_all_tasks:
            res = purge_all_tasks()
            if inspect.isawaitable(res):
                await res
            count = len(lst)
            TASKS_CACHE[chat_id] = []
            # –ù–ï —á–∏—Å—Ç–∏–º SUPPLY_EVENTS, APPS_CACHE, NOTIFIED_CREATED ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞—è–≤–∫–∏
            return count
    except Exception as e:
        log.warning("purge_all_tasks failed: %s", e)
    # –ò–Ω–∞—á–µ ‚Äî —É–¥–∞–ª—è–µ–º –∫–∞–∂–¥—É—é –ø–æ ID
    for t in lst:
        tid = str(t.get("id") or "")
        try:
            if tid:
                ok = await delete_task_by_id(tid)
                if ok:
                    count += 1
                    _remove_task_from_caches(chat_id, tid)
        except Exception:
            pass
    return count

# ==== –§–∏–ª—å—Ç—Ä—ã –∑–∞–¥–∞—á/–∑–∞—è–≤–æ–∫ ====
def is_active_task(t:dict)->bool:
    """
    –ê–∫—Ç–∏–≤–Ω–∞—è (–Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω–∞—è) –∑–∞–¥–∞—á–∞: –ø—Ä–µ–¥-–∑–∞—è–≤–æ—á–Ω—ã–µ —Å—Ç–∞–¥–∏–∏,
    –∏—Å–∫–ª—é—á–∞—è –æ—à–∏–±–∫–∏/–æ—Ç–º–µ–Ω—ã –∏ –∏—Å–∫–ª—é—á–∞—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ/—Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞—è–≤–æ–∫.
    """
    status=(t.get("status") or t.get("state") or "").upper().strip()
    if not status:
        return True
    if status in ERROR_STATUSES or status in CANCEL_STATUSES:
        return False
    # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç–∞–¥–∏–∏ –∑–∞—è–≤–æ–∫ –∏–∑ —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á:
    if status in APPLICATION_FILL_STATUSES:  # ORDER_DATA_FILLING
        return False
    if status in CREATING_STATUSES or status in CREATED_STATUSES or status in DONE_STATUSES:
        return False
    # –û—Å—Ç–∞–≤–ª—è–µ–º DRAFT/WAIT/SLOT/..., –≤–∫–ª—é—á–∞—è SUPPLY_ORDER_FETCH/POLL_SUPPLY
    return True

def is_application_task(t:dict)->bool:
    """
    –ó–∞—è–≤–∫–∞: –Ω–∞—á–∏–Ω–∞—è —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è (ORDER_DATA_FILLING), —Å–æ–∑–¥–∞–Ω–∏–µ (CREATING_*),
    —Å–æ–∑–¥–∞–Ω–æ (CREATED/UI_STATUS_CREATED/–°–û–ó–î–ê–ù–û) –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ DONE/SUCCESS/COMPLETED.
    –û—à–∏–±–∫–∏/–æ—Ç–º–µ–Ω—ã –∏—Å–∫–ª—é—á–µ–Ω—ã.
    """
    status=(t.get("status") or t.get("state") or "").upper().strip()
    if not status:
        return False
    if status in ERROR_STATUSES or status in CANCEL_STATUSES:
        return False
    if status in APPLICATION_FILL_STATUSES:
        return True
    if status in CREATING_STATUSES:
        return True
    if status in CREATED_STATUSES:
        return True
    if status in DONE_STATUSES:
        return True
    return False

def is_created_like(t:dict)->bool:
    """
    –ß—Ç–æ —Å—á–∏—Ç–∞–µ–º —Å–æ–±—ã—Ç–∏–µ–º ¬´—Å–æ–∑–¥–∞–Ω–∏—è¬ª –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è:
    - ORDER_DATA_FILLING (–Ω–∞—á–∞–ª–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è) ‚Äî –ø–æ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–µ —ç—Ç–æ —É–∂–µ ¬´—Å–æ–∑–¥–∞–Ω–æ¬ª;
    - CREATED/UI_STATUS_CREATED/–°–û–ó–î–ê–ù–û;
    - DONE/SUCCESS/COMPLETED/SUPPLY_CREATED.
    –û—à–∏–±–∫–∏/–æ—Ç–º–µ–Ω—ã ‚Äî –Ω–µ—Ç.
    """
    s=(t.get("status") or t.get("state") or "").upper().strip()
    if not s: return False
    if s in CANCEL_STATUSES or s in ERROR_STATUSES: return False
    return (s in APPLICATION_FILL_STATUSES) or (s in CREATED_STATUSES) or (s in DONE_STATUSES)

# ==== Keyboards (–∑–∞–¥–∞—á–∏/–∑–∞—è–≤–∫–∏) ====
def build_tasks_kb(n:int)->InlineKeyboardMarkup:
    rows=[]; buf=[]
    # –ö–Ω–æ–ø–∫–∏ –≤—ã–±–æ—Ä–∞ –ø–æ –Ω–æ–º–µ—Ä—É
    for i in range(1,n+1):
        buf.append(InlineKeyboardButton(text=str(i),callback_data=f"tasks:detail:{i}"))
        if len(buf)==5: rows.append(buf); buf=[]
    if buf: rows.append(buf)
    # –£–ø—Ä–∞–≤–ª—è—é—â–∏–µ –∫–Ω–æ–ø–∫–∏
    ctrl_row = [
        InlineKeyboardButton(text=f"{EMOJI_REFRESH} –û–±–Ω–æ–≤–∏—Ç—å",callback_data="tasks:refresh"),
        InlineKeyboardButton(text="üóë –£–¥–∞–ª–∏—Ç—å –≤—Å–µ",callback_data="tasks:delete_all"),
        InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å",callback_data="tasks:close"),
    ]
    rows.append(ctrl_row)
    return InlineKeyboardMarkup(inline_keyboard=rows)

def task_detail_kb(tid:str)->InlineKeyboardMarkup:
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üóë –£–¥–∞–ª–∏—Ç—å",callback_data=f"tasks:delete_id:{tid}")],
        [InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥",callback_data="tasks:refresh")],
        [InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å",callback_data="tasks:close")]
    ])

def build_apps_kb(n:int)->InlineKeyboardMarkup:
    rows=[]; buf=[]
    for i in range(1,n+1):
        buf.append(InlineKeyboardButton(text=str(i),callback_data=f"apps:detail:{i}"))
        if len(buf)==6: rows.append(buf); buf=[]
    if buf: rows.append(buf)
    rows.append([
        InlineKeyboardButton(text=f"{EMOJI_REFRESH} –û–±–Ω–æ–≤–∏—Ç—å",callback_data="apps:refresh"),
        InlineKeyboardButton(text="‚¨Ö –ú–µ–Ω—é",callback_data="back:menu"),
        InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å",callback_data="apps:close"),
    ])
    return InlineKeyboardMarkup(inline_keyboard=rows)

def apps_detail_kb()->InlineKeyboardMarkup:
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥ –∫ –∑–∞—è–≤–∫–∞–º",callback_data="apps:refresh")],
        [InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å",callback_data="apps:close")]
    ])

# ==== Notifications (Created application) ====
def build_created_notification_text(t:Dict[str,Any], chat_id:int)->str:
    tid=t.get("id") or "-"
    date=t.get("date") or (t.get("desired_from_iso","")[:10] if t.get("desired_from_iso") else "-")
    slot=_human_window(t.get("timeslot") or "", t.get("desired_from_iso") or "", t.get("desired_to_iso") or "")
    wh=_task_warehouse_name(t)
    cd=_resolve_crossdock_name_warehouses(t, chat_id)
    qty=_sum_qty(t)
    lines=[
        f"üìÑ ¬ß¬ßB¬ß¬ß–ó–∞—è–≤–∫–∞ —Å–æ–∑–¥–∞–Ω–∞¬ß¬ßEB¬ß¬ß",
        SEP_THIN,
        f"ID: ¬ß¬ßB¬ß¬ß{tid}¬ß¬ßEB¬ß¬ß",
        f"–°—Ç–∞—Ç—É—Å: ‚úÖ –°–æ–∑–¥–∞–Ω–æ",
        f"–î–∞—Ç–∞: {date} | –û–∫–Ω–æ: {slot}",
        f"–°–∫–ª–∞–¥ –ø–æ—Å—Ç–∞–≤–∫–∏: ¬ß¬ßB¬ß¬ß{html.escape(wh)}¬ß¬ßEB¬ß¬ß",
        f"–ö—Ä–æ—Å—Å–¥–æ–∫: ¬ß¬ßB¬ß¬ß{html.escape(cd)}¬ß¬ßEB¬ß¬ß",
        f"–ò—Ç–æ–≥–æ: ¬ß¬ßB¬ß¬ß{qty} —à—Ç¬ß¬ßEB¬ß¬ß",
        ""
    ]
    sl=t.get("sku_list") or []
    if isinstance(sl,list) and sl:
        lines.append("–ü–æ–∑–∏—Ü–∏–∏:")
        for it in sl[:30]:
            sku=it.get("sku")
            q=it.get("total_qty") or it.get("qty") or 0
            sname=get_sku_name_local(int(sku)) if sku else "-"
            lines.append(f"‚Ä¢ ¬ß¬ßB¬ß¬ß{html.escape(sname)}¬ß¬ßEB¬ß¬ß (SKU {sku}) ‚Äî {q} —à—Ç")
        lines.append("")
    if lines and lines[-1]=="":
        lines.pop()
    lines.append(SEP_THIN)
    return build_html(lines)

async def scan_and_notify_created(chat_id:int, tasks:List[Dict[str,Any]]):
    """
    –ù–∞—Ö–æ–¥–∏—Ç ¬´—Å–æ–∑–¥–∞–Ω–Ω—ã–µ¬ª –∑–∞—è–≤–∫–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑.
    """
    sent=0
    for t in tasks:
        try:
            tid=str(t.get("id") or "")
            if not tid:
                continue
            if not is_created_like(t):
                continue
            if tid in NOTIFIED_CREATED:
                continue
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            text=build_created_notification_text(t, chat_id)
            await send_long(chat_id, text)
            NOTIFIED_CREATED.add(tid)
            # –ª–æ–≥-—Å–æ–±—ã—Ç–∏–µ
            try:
                _supply_log_append(chat_id, {
                    "status": "CREATED",
                    "text": "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞—è–≤–∫–∏",
                    "payload": t
                })
            except Exception:
                pass
            sent+=1
        except Exception as e:
            log.warning("notify created failed: %s", e)
    if sent:
        save_state()

# ==== Analyze / snapshot / daily notify ====
async def _ensure_deficit_cache_for_chat(chat_id: int) -> Dict[str, Any]:
    """
    Ensure LAST_DEFICIT_CACHE has valid data for the given chat.
    If missing, performs a fast recomputation and stores the result.
    Returns the cache dict with keys: flat, timestamp, report, raw_rows, consumption_cache.
    """
    cache = LAST_DEFICIT_CACHE.get(chat_id)
    if cache and cache.get("flat"):
        return cache
    
    # Cache missing or empty - recompute
    log.info("Deficit cache missing for chat %s, recomputing...", chat_id)
    try:
        await ensure_sku_names(force=True)
        rows, err = await ozon_stock_fbo(SKU_LIST)
        if err:
            log.warning("Failed to fetch stock for deficit cache: %s", err)
            return {}
        ccache = build_consumption_cache()
        report, flat = generate_deficit_report(rows, SKU_NAME_CACHE, ccache)
        cache = {
            "flat": flat,
            "timestamp": int(time.time()),
            "report": report,
            "raw_rows": rows,
            "consumption_cache": ccache
        }
        LAST_DEFICIT_CACHE[chat_id] = cache
        log.info("Deficit cache recomputed for chat %s: %d items", chat_id, len(flat))
        return cache
    except Exception as e:
        log.exception("Failed to ensure deficit cache for chat %s: %s", chat_id, e)
        return {}

async def handle_analyze(chat_id:int, verbose:bool=True):
    global LAST_ANALYZE_MS,LAST_ANALYZE_ERROR
    async with ANALYZE_LOCK:
        start=time.time(); LAST_ANALYZE_ERROR=None; temp=None
        try:
            if verbose: temp=await send_safe_message(chat_id,"‚öô –ê–Ω–∞–ª–∏–∑ –∑–∞–ø–∞—Å–æ–≤‚Ä¶")
            need_snapshot=(time.time()-LAST_SNAPSHOT_TS>SNAPSHOT_STALE_MINUTES*60)
            rows,err=await ozon_stock_fbo(SKU_LIST)
            if err:
                LAST_ANALYZE_ERROR=err
                await send_safe_message(chat_id,f"–û—à–∏–±–∫–∞ Ozon API: {html.escape(err)}")
                if temp:
                    try: await temp.delete()
                    except Exception: pass
                return
            if need_snapshot and time.time()-LAST_SNAPSHOT_TS>SNAPSHOT_MIN_REUSE_SECONDS:
                append_snapshot(rows); await flush_history_if_needed(force=True)
            await ensure_sku_names(force=True)
            ccache=build_consumption_cache()
            report,flat=generate_deficit_report(rows,SKU_NAME_CACHE,ccache)
            LAST_DEFICIT_CACHE[chat_id]={"flat":flat,"timestamp":int(time.time()),"report":report,"raw_rows":rows,"consumption_cache":ccache}
            try: build_fact_index(rows,flat,ccache)
            except Exception as e: log.warning("FACT_INDEX build error: %s", e)
            kb=InlineKeyboardMarkup(inline_keyboard=[
                [InlineKeyboardButton(text="–í—Å–µ",callback_data="filter:all"),
                 InlineKeyboardButton(text="–ö—Ä–∏—Ç–∏—á–Ω–æ",callback_data="filter:crit"),
                 InlineKeyboardButton(text="50‚Äì80%",callback_data="filter:mid")],
                [InlineKeyboardButton(text=f"{EMOJI_REFRESH} –û–±–Ω–æ–≤–∏—Ç—å",callback_data="action:reanalyze")],
                [InlineKeyboardButton(text="–ê–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",callback_data="menu_autobook")],
            ])
            await send_long(chat_id,report,kb=kb if flat else None)
            if temp:
                try: await temp.delete()
                except Exception: pass
        except Exception as e:
            LAST_ANALYZE_ERROR=str(e)
            log.exception("Analyze error")
            await send_safe_message(chat_id,f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {html.escape(str(e))}")
        finally:
            LAST_ANALYZE_MS=(time.time()-start)*1000
            await flush_history_if_needed()

async def snapshot_job():
    if time.time()-LAST_SNAPSHOT_TS<SNAPSHOT_MIN_REUSE_SECONDS: return
    rows,err=await ozon_stock_fbo(SKU_LIST)
    if err or not rows: return
    append_snapshot(rows)
    await ensure_sku_names(force=True)
    try:
        ccache=build_consumption_cache(); build_fact_index(rows,[],ccache)
    except Exception as e: log.warning("snapshot index build fail: %s", e)
    await flush_history_if_needed(force=True)

async def daily_notify_job():
    await ensure_fact_index()
    async with ANALYZE_LOCK:
        rows,err=await ozon_stock_fbo(SKU_LIST)
        if err:
            if ADMIN_ID:
                await send_safe_message(ADMIN_ID,f"–û—à–∏–±–∫–∞ Ozon API: {html.escape(err)}")
            return
        if time.time()-LAST_SNAPSHOT_TS>SNAPSHOT_MIN_REUSE_SECONDS:
            append_snapshot(rows); await flush_history_if_needed(force=True)
        await ensure_sku_names(force=True)
        ccache=build_consumption_cache()
        report,flat=generate_deficit_report(rows,SKU_NAME_CACHE,ccache)
        try: build_fact_index(rows,flat,ccache)
        except Exception as e: log.warning("FACT_INDEX daily build fail: %s", e)
        header=f"{EMOJI_NOTIFY} <b>–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á—ë—Ç {DAILY_NOTIFY_HOUR:02d}:{DAILY_NOTIFY_MINUTE:02d}</b>\n"
        kb=InlineKeyboardMarkup(inline_keyboard=[
            [InlineKeyboardButton(text="–í—Å–µ",callback_data="filter:all"),
             InlineKeyboardButton(text="–ö—Ä–∏—Ç–∏—á–Ω–æ",callback_data="filter:crit"),
             InlineKeyboardButton(text="50‚Äì80%",callback_data="filter:mid")],
            [InlineKeyboardButton(text=f"{EMOJI_REFRESH} –û–±–Ω–æ–≤–∏—Ç—å",callback_data="action:reanalyze")],
        ])
        targets=list(KNOWN_USERS) or ([ADMIN_ID] if ADMIN_ID else [])
        for uid in targets:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –∫—ç—à –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ —É –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è
            LAST_DEFICIT_CACHE[uid]={"flat":flat,"timestamp":int(time.time()),"report":report,"raw_rows":rows,"consumption_cache":ccache}
            try:
                await send_long(uid, header+report, kb=kb)
            except Exception as e:
                log.warning("daily notify fail to %s: %s", uid, e)
        await flush_history_if_needed()

async def maintenance_job():
    prune_history()
    await flush_history_if_needed()

async def init_snapshot():
    rows,err=await ozon_stock_fbo(SKU_LIST)
    if err or not rows: return
    append_snapshot(rows)
    await ensure_sku_names(force=True)
    try:
        ccache=build_consumption_cache(); build_fact_index(rows,[],ccache)
    except Exception as e: log.warning("init index build fail: %s", e)
    await flush_history_if_needed(force=True)

# ==== Crossdock selection with robust parsing ====
def _parse_crossdock_env(raw:str)->Dict[str,str]:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã:
     - 'ID:NAME,ID2:NAME2'
     - 'NAME ID' –∏–ª–∏ 'ID NAME'
     - –°—Ç—Ä–æ–∫–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é/—Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π/–ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict[id] = name
    """
    m: Dict[str,str] = {}
    if not raw:
        return m
    parts = re.split(r"[,\n;]+", raw)
    for p in parts:
        s=p.strip()
        if not s: continue
        if ":" in s:
            left,right=s.split(":",1)
            left=left.strip(); right=right.strip()
            if re.fullmatch(r"\d{10,}", left):
                m[left]=right
            elif re.fullmatch(r"\d{10,}", right):
                m[right]=left
        else:
            toks=re.split(r"\s+", s)
            if len(toks)>=2:
                if re.fullmatch(r"\d{10,}", toks[0]):
                    _id=toks[0]; name=" ".join(toks[1:])
                    m[_id]=name
                elif re.fullmatch(r"\d{10,}", toks[-1]):
                    _id=toks[-1]; name=" ".join(toks[:-1])
                    m[_id]=name
    return m

CROSSDOCK_RAW = os.getenv("CROSSDOCK_WAREHOUSES","").strip()
CROSSDOCK_MAP: Dict[str,str] = _parse_crossdock_env(CROSSDOCK_RAW)
if DEFAULT_DROPOFF_ID:
    CROSSDOCK_MAP.setdefault(DEFAULT_DROPOFF_ID, DEFAULT_DROPOFF_NAME or "DROP_OFF")

def crossdock_kb()->InlineKeyboardMarkup:
    rows=[]
    if CROSSDOCK_MAP:
        for wid,name in CROSSDOCK_MAP.items():
            title = f"{name} ({wid})" if name else str(wid)
            rows.append([InlineKeyboardButton(text=title[:64], callback_data=f"cdsel:{wid}")])
    else:
        rows.append([InlineKeyboardButton(text="–ù–µ—Ç –∫—Ä–æ—Å—Å–¥–æ–∫-—Å–∫–ª–∞–¥–æ–≤ (–¥–æ–±–∞–≤—å—Ç–µ CROSSDOCK_WAREHOUSES –≤ .env)", callback_data="noop")])
    rows.append([InlineKeyboardButton(text="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", callback_data="cdsel:skip")])
    return InlineKeyboardMarkup(inline_keyboard=rows)

@dp.callback_query(F.data=="menu_autobook")
async def cb_menu_autobook(c:CallbackQuery,state:FSMContext):
    ensure_admin(c.from_user.id)
    await state.set_state(AutobookStates.choose_crossdock)
    await c.message.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Å–∫–ª–∞–¥ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–∫—Ä–æ—Å—Å–¥–æ–∫):", reply_markup=crossdock_kb())
    await c.answer()

@dp.callback_query(F.data.startswith("cdsel:"))
async def cb_crossdock_pick(c:CallbackQuery,state:FSMContext):
    ensure_admin(c.from_user.id)
    choice=c.data.split(":",1)[1]
    if choice=="skip":
        cd_id=""; cd_name=""
        await c.answer("–ö—Ä–æ—Å—Å–¥–æ–∫ –ø—Ä–æ–ø—É—â–µ–Ω")
    else:
        cd_id=choice; cd_name=CROSSDOCK_MAP.get(choice,"")
        await c.answer(f"–ö—Ä–æ—Å—Å–¥–æ–∫: {cd_name or cd_id}")
    CROSSDOCK_SELECTED[c.message.chat.id]={"id":cd_id,"name":cd_name}
    await state.update_data(crossdock_id=cd_id, crossdock_name=cd_name)
    if sw and hasattr(sw, "set_global_crossdock"):
        try:
            sw.set_global_crossdock(cd_id or None, cd_name or None)
            log.info("Global crossdock set in supply_watch: %s (%s)", cd_name, cd_id)
        except Exception as e:
            log.warning("set_global_crossdock failed: %s", e)
    if AUTOBOOK_ENABLED and abf:
        for fn_name in ("set_crossdock","set_crossdock_context","set_crossdock_for_chat","set_dropoff","set_drop_off","set_drop_off_id","set_global_crossdock"):
            if hasattr(abf, fn_name):
                try:
                    getattr(abf, fn_name)(c.message.chat.id, cd_id, cd_name)
                    log.info("Crossdock passed to external via %s", fn_name)
                    break
                except Exception as e:
                    log.warning("Crossdock external setter error: %s", e)
    await state.set_state(AutobookStates.after_crossdock)
    kb=InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–ù–∞—á–∞—Ç—å –º–∞—Å—Ç–µ—Ä", callback_data="ab_start")],
        [InlineKeyboardButton(text="–û—Ç–º–µ–Ω–∞", callback_data="ab_cancel")]
    ])
    await c.message.answer(f"–ì–æ—Ç–æ–≤–æ. –ö—Ä–æ—Å—Å–¥–æ–∫: {cd_name or '‚Äî'}.\n–ù–∞–∂–º–∏—Ç–µ '–ù–∞—á–∞—Ç—å –º–∞—Å—Ç–µ—Ä' —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.", reply_markup=kb)

@dp.callback_query(F.data=="ab_cancel")
async def cb_autobook_cancel(c:CallbackQuery,state:FSMContext):
    await state.clear()
    await c.message.answer("–ê–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
    await c.answer()

@dp.callback_query(F.data=="ab_start")
async def cb_autobook_start(c:CallbackQuery,state:FSMContext):
    ensure_admin(c.from_user.id)
    data=await state.get_data()
    cd_id=data.get("crossdock_id",""); cd_name=data.get("crossdock_name","")
    await ensure_sku_names(force=True)
    try_mount_external_name_resolver()
    if sw and hasattr(sw, "set_global_crossdock"):
        try:
            sw.set_global_crossdock(cd_id or None, cd_name or None)
        except Exception:
            pass
    if AUTOBOOK_ENABLED and autobook_router is not None and hasattr(abf,"start_autobook"):
        try:
            await abf.start_autobook(chat_id=c.message.chat.id, crossdock_id=cd_id, crossdock_name=cd_name)
            await c.message.answer("–í–Ω–µ—à–Ω–∏–π –º–∞—Å—Ç–µ—Ä –∑–∞–ø—É—â–µ–Ω.")
            # –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ-–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–¥–∞—á –º–∞—Å—Ç–µ—Ä–æ–º
            try:
                import supply_watch as swm
                if hasattr(swm, "enable_auto_watch_for_chat"):
                    swm.enable_auto_watch_for_chat(c.message.chat.id, True)
            except Exception:
                pass
        except Exception as e:
            await c.message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤–Ω–µ—à–Ω–∏–π –º–∞—Å—Ç–µ—Ä: {e}\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /autobook –¥–ª—è fallback.")
    else:
        await c.message.answer("Fallback –º–∞—Å—Ç–µ—Ä: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /autobook –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —à–∞–≥–∏).")
    await state.clear()
    await c.answer()

# ==== Main menu keyboard ====
def main_menu_kb()->ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(keyboard=[
        [KeyboardButton(text="üîß –ê–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"),
         KeyboardButton(text=f"{EMOJI_LIST} –ó–∞—è–≤–∫–∏"),
         KeyboardButton(text=f"{EMOJI_TASKS} –ó–∞–¥–∞—á–∏")],
        [KeyboardButton(text="üîç –ê–Ω–∞–ª–∏–∑"),
         KeyboardButton(text="ü§ñ AI —á–∞—Ç")],
        [KeyboardButton(text="üì¶ –¢–æ–≤–∞—Ä—ã"),
         KeyboardButton(text="üè¨ –°–∫–ª–∞–¥—ã"),
         KeyboardButton(text="üó∫ –ö–ª–∞—Å—Ç–µ—Ä—ã")],
        [KeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞")],
    ], resize_keyboard=True)

def start_overview()->str:
    rows=[
        ("üîç –ê–Ω–∞–ª–∏–∑","–ü–µ—Ä–µ—Å—á—ë—Ç –¥–µ—Ñ–∏—Ü–∏—Ç–æ–≤"),
        ("üì¶ –¢–æ–≤–∞—Ä—ã","–°–ø–∏—Å–æ–∫ SKU (–∏–º–µ–Ω–∞)"),
        ("üè¨ –°–∫–ª–∞–¥—ã","–û—Å—Ç–∞—Ç–∫–∏ –ø–æ —Å–∫–ª–∞–¥–∞–º"),
        ("üó∫ –ö–ª–∞—Å—Ç–µ—Ä—ã","–ì—Ä—É–ø–ø—ã —Å–∫–ª–∞–¥–æ–≤"),
        ("üìÑ –ó–∞—è–≤–∫–∏","–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞—è–≤–∫–∏"),
        ("üìã –ó–∞–¥–∞—á–∏","–ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ (–¥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è)"),
        ("ü§ñ AI —á–∞—Ç","FACT / GENERAL –¥–∏–∞–ª–æ–≥"),
        ("üîß –ê–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ","–í—ã–±–æ—Ä –∫—Ä–æ—Å—Å–¥–æ–∫–∞ + –º–∞—Å—Ç–µ—Ä"),
        ("‚ùå –û—Ç–º–µ–Ω–∞","–°–±—Ä–æ—Å FSM / AI"),
    ]
    lines=[]
    header=f"{'‚ïê'*22}  {EMOJI_INFO} –û–ë–ó–û–†  {'‚ïê'*22}"
    lines.append(header)
    lines.append(f"–í–µ—Ä—Å–∏—è: {VERSION} | ChatMode={BOT_STATE.get('chat_mode','?').upper()} | Style={'ON' if BOT_STATE.get('style_enabled') else 'OFF'} | ClusterView={BOT_STATE.get('cluster_view_mode')}")
    lines.append(SEP_THIN)
    cmds=["tasks","all_tasks","autobook","analyze","stock","warehouses","clusters","supplies","ai","ask","chat_mode","ai_reset_token"]
    lines.append("–ö–æ–º–∞–Ω–¥—ã: "+ " /".join(f"/{c}" for c in cmds))
    lines.append(SEP_THIN)
    ml=max(len(k) for k,_ in rows)
    for k,d in rows:
        lines.append(f"{k}{' '*(ml-len(k))} ‚îÇ {d}")
    lines.append(SEP_THIN)
    lines.append(f"Autobook: {'external' if AUTOBOOK_ENABLED else 'fallback'} | –ö—Ä–æ—Å—Å–¥–æ–∫–æ–≤: {len(CROSSDOCK_MAP)}")
    lines.append("‚ïê"*len(header))
    return build_html(lines)

def version_info()->str:
    import sys
    return (f"–í–µ—Ä—Å–∏—è: {VERSION}\nPython: {sys.version.split()[0]}\nSnapshots: {len(HISTORY_CACHE)}\n"
            f"SKU index: {len(FACT_INDEX.get('sku', {}))}\nClusters: {len(FACT_INDEX.get('cluster', {}))}\n"
            f"ChatMode: {BOT_STATE.get('chat_mode')} Style:{BOT_STATE.get('style_enabled')} "
            f"ClusterView:{BOT_STATE.get('cluster_view_mode')} Autobook={'external' if AUTOBOOK_ENABLED else 'fallback'}")

# ==== Diagnostics & supplies summary ====
def build_diag_report()->str:
    inv=FACT_INDEX.get("inventory_overview",{})
    sku_section=FACT_INDEX.get("sku",{})
    top_def=FACT_INDEX.get("top_deficits",[])
    top_wh=FACT_INDEX.get("top_warehouses",[])
    top_cl=FACT_INDEX.get("top_clusters",[])
    cov={"<25":0,"25-50":0,"50-80":0,"80-100":0,"100+":0}
    for _,info in sku_section.items():
        cv=info["worst_coverage"]
        if cv<0.25: cov["<25"]+=1
        elif cv<0.5: cov["25-50"]+=1
        elif cv<0.8: cov["50-80"]+=1
        elif cv<1: cov["80-100"]+=1
        else: cov["100+"]+=1
    s=lambda t:f"¬ß¬ßB¬ß¬ß{t}¬ß¬ßEB¬ß¬ß"
    lines=[f"{EMOJI_DIAG} {s('–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞')} ({time.strftime('%H:%M:%S')})",SEP_BOLD,
           f"{EMOJI_INFO} –í–µ—Ä—Å–∏—è: {VERSION}",
           f"{EMOJI_CLOUD} –°–Ω–∏–º–æ–∫: {FACT_INDEX.get('snapshot_ts','-')} | SKU: {inv.get('total_sku','-')} | –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(FACT_INDEX.get('cluster',{}))}",
           f"{EMOJI_CHAT} ChatMode={BOT_STATE.get('chat_mode')} | Style={'ON' if BOT_STATE.get('style_enabled') else 'OFF'} | Autobook={'external' if AUTOBOOK_ENABLED else 'fallback'}",
           "", s("–ü–æ–∫—Ä—ã—Ç–∏–µ (—Ö—É–¥—à–µ–µ –ø–æ SKU)"), SEP_THIN,
           f"<25%: {cov['<25']} | 25‚Äì50%: {cov['25-50']} | 50‚Äì80%: {cov['50-80']} | 80‚Äì100%: {cov['80-100']} | ‚â•100%: {cov['100+']}",
           "", s("–¢–æ–ø –¥–µ—Ñ–∏—Ü–∏—Ç–Ω—ã—Ö SKU"), SEP_THIN]
    if top_def:
        for td in top_def[:8]:
            lines.append(f"‚Ä¢ {td['name'][:40]} (SKU {td['sku']}) –ø–æ–∫—Ä—ã—Ç–∏–µ {td['coverage']:.2f} –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å {td['deficit_need']}")
    else:
        lines.append("–ù–µ—Ç –¥–µ—Ñ–∏—Ü–∏—Ç–∞.")
    lines.append("")
    lines+=[s("–°–∫–ª–∞–¥—ã —Å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å—é"), SEP_THIN]
    if top_wh:
        for w in top_wh[:6]:
            lines.append(f"‚Ä¢ {bold(w['name'][:40])}: –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å {w['total_need']}, –¥–µ—Ñ–∏—Ü–∏—Ç {w['deficit_need']}")
    else:
        lines.append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
    lines.append("")
    lines+=[s("–ö–ª–∞—Å—Ç–µ—Ä—ã —Å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å—é"), SEP_THIN]
    if top_cl:
        for c in top_cl[:6]:
            lines.append(f"‚Ä¢ {bold(c['name'][:40])}: –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å {c['total_need']}, –¥–µ—Ñ–∏—Ü–∏—Ç {c['deficit_need']}")
    else:
        lines.append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
    lines.append("")
    lines+=[s("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"), SEP_THIN,
            f"API: {LAST_API_LATENCY_MS:.0f} –º—Å | –ê–Ω–∞–ª–∏–∑: {LAST_ANALYZE_MS:.0f} –º—Å | –û—à–∏–±–∫–∞: {LAST_ANALYZE_ERROR or '‚Äî'}",
            f"Snapshots: {len(HISTORY_CACHE)} | –ö—ç—à AI: {len(ANSWER_CACHE)}"]
    return build_html(lines)

def build_supplies_last_created(limit:int=3)->str:
    """
    Build text for last created applications. Shows last 3 created entries with both 
    sides (warehouse + crossdock) and explicit status labels.
    """
    arr=SUPPLY_EVENTS.get("*") or []
    try:
        loop=asyncio.get_running_loop()
        if loop.is_running():
            loop.create_task(ensure_sku_names(force=True))
    except Exception:
        pass
    if not arr:
        return build_html([f"{EMOJI_LIST} –ù–µ—Ç —Å–æ–±—ã—Ç–∏–π –ø–æ –∑–∞—è–≤–∫–∞–º."])
    created=[]; seen=set()
    for e in reversed(arr):
        payload=e.get("payload") or {}
        tid=payload.get("id") or payload.get("task_id") or ""
        if not tid or tid in seen: continue
        text=(e.get("text") or "")
        status=(e.get("status") or "")
        # Include ORDER_DATA_FILLING as created state
        if "—Å–æ–∑–¥–∞–Ω" in text.lower() or status.lower() in ("—Å–æ–∑–¥–∞–Ω–æ","created","done","success","finished","completed","supply_created","order_data_filling"):
            seen.add(tid); created.append(e)
            if len(created)>=limit: break
    if not created:
        return build_html([f"{EMOJI_LIST} –ü–æ–∫–∞ –Ω–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫."])
    lines=[f"{EMOJI_LIST} ¬ß¬ßB¬ß¬ß–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞—è–≤–∫–∏ ({len(created)})¬ß¬ßEB¬ß¬ß", SEP_THIN]
    for e in created:
        payload=e.get("payload") or {}
        tid=payload.get("id") or payload.get("task_id") or "-"
        sku_list=payload.get("sku_list") or []
        qty=sum(int(it.get("qty") or it.get("total_qty") or 0) for it in sku_list)
        wh=payload.get("warehouse_name") or payload.get("drop_off_name") or "-"
        cd=payload.get("crossdock_name") or payload.get("crossdock_id") or ""
        slot=_human_window(payload.get("timeslot") or "", payload.get("desired_from_iso") or "", payload.get("desired_to_iso") or "")
        # Determine status label
        status_text = (e.get("status") or "").lower()
        if status_text in ("done", "success", "finished", "completed"):
            status_label = "–°—Ç–∞—Ç—É—Å: ‚úÖ –ì–æ—Ç–æ–≤–æ"
        else:
            status_label = "–°—Ç–∞—Ç—É—Å: ‚úÖ –°–æ–∑–¥–∞–Ω–æ"
        lines.append(f"ID: ¬ß¬ßB¬ß¬ß{tid}¬ß¬ßEB¬ß¬ß | ¬ß¬ßB¬ß¬ß{qty} —à—Ç¬ß¬ßEB¬ß¬ß | –û–∫–Ω–æ: {html.escape(slot)}")
        lines.append(status_label)
        lines.append(f"–°–∫–ª–∞–¥ –ø–æ—Å—Ç–∞–≤–∫–∏: ¬ß¬ßB¬ß¬ß{html.escape(wh)}¬ß¬ßEB¬ß¬ß | –ö—Ä–æ—Å—Å–¥–æ–∫: ¬ß¬ßB¬ß¬ß{html.escape(cd)}¬ß¬ßEB¬ß¬ß")
        if sku_list:
            lines.append("–ü–æ–∑–∏—Ü–∏–∏:")
            for it in sku_list[:30]:
                sku=it.get("sku"); q=it.get("qty") or it.get("total_qty") or 0
                sname=get_sku_name_local(int(sku)) if sku else "-"
                lines.append(f"‚Ä¢ ¬ß¬ßB¬ß¬ß{html.escape(sname)}¬ß¬ßEB¬ß¬ß (SKU {sku}) ‚Äî {q} —à—Ç")
        lines.append("")
    if lines and lines[-1]=="":
        lines.pop()
    lines.append(SEP_THIN)
    return build_html(lines)

# ==== Utility: ensure_admin ====
def ensure_admin(uid:int):
    global ADMIN_ID
    if ADMIN_ID is None:
        ADMIN_ID=uid
    KNOWN_USERS.add(uid); save_known_users()

# ==== Stock/Warehouses/Clusters render helpers ====
async def render_stock_list(chat_id:int, edit_message:Optional[Message]=None):
    await ensure_sku_names(force=True)
    await ensure_fact_index()
    total=len(SKU_LIST)
    if total==0:
        kb=InlineKeyboardMarkup(inline_keyboard=[[InlineKeyboardButton(text="–ù–µ—Ç SKU",callback_data="noop")],
                                                 [InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥", callback_data="back:menu")]])
        text=f"{EMOJI_BOX} –¢–æ–≤–∞—Ä—ã:"
        if edit_message:
            try:
                await edit_message.edit_text(text, reply_markup=kb)
                return
            except Exception:
                pass
        await send_safe_message(chat_id, text, reply_markup=kb)
        return

    start=0; end=min(start+STOCK_PAGE_SIZE,total)
    btn=[]
    for sku in SKU_LIST[start:end]:
        nm=SKU_NAME_CACHE.get(sku,f"SKU {sku}")
        btn.append([InlineKeyboardButton(text=f"{nm[:48]} (SKU {sku})",callback_data=f"sku:{sku}")])
    nav=[InlineKeyboardButton(text=f"1/{(total+STOCK_PAGE_SIZE-1)//STOCK_PAGE_SIZE}",callback_data="noop")]
    btn.append(nav)
    btn.append([InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥", callback_data="back:menu")])
    kb=InlineKeyboardMarkup(inline_keyboard=btn)
    text=f"{EMOJI_BOX} –¢–æ–≤–∞—Ä—ã:"
    if edit_message:
        try:
            await edit_message.edit_text(text, reply_markup=kb)
            return
        except Exception:
            pass
    await send_safe_message(chat_id, text, reply_markup=kb)

async def render_warehouses_list(chat_id:int, edit_message:Optional[Message]=None):
    await ensure_sku_names(force=True)
    rows, err=await ozon_stock_fbo(SKU_LIST)
    if err:
        await send_safe_message(chat_id, f"–û—à–∏–±–∫–∞ Ozon API: {html.escape(err)}")
        return
    agg=aggregate_rows(rows); wh_map={}
    for wmap in agg.values():
        for wk,info in wmap.items():
            wh_map.setdefault(wk,info["warehouse_name"])
    if not wh_map:
        kb=InlineKeyboardMarkup(inline_keyboard=[[InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥", callback_data="back:menu")]])
        text=f"{EMOJI_WH} –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–∫–ª–∞–¥–∞–º."
        if edit_message:
            try: await edit_message.edit_text(text, reply_markup=kb)
            except Exception: pass
        else:
            await send_safe_message(chat_id, text, reply_markup=kb)
        return
    kb_rows=[]
    WAREHOUSE_CB_MAP.clear()
    for wk,nm in sorted(wh_map.items(), key=lambda x:x[1].lower()):
        hid=hashlib.sha1(str(wk).encode()).hexdigest()[:10]
        WAREHOUSE_CB_MAP[hid]=(wk,nm)
        kb_rows.append([InlineKeyboardButton(text=nm[:60],callback_data=f"whid:{hid}")])
    kb_rows.append([InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥", callback_data="back:menu")])
    kb=InlineKeyboardMarkup(inline_keyboard=kb_rows)
    text=f"{EMOJI_WH} –°–∫–ª–∞–¥—ã:"
    if edit_message:
        try: await edit_message.edit_text(text, reply_markup=kb)
        except Exception: pass
    else:
        await send_safe_message(chat_id, text, reply_markup=kb)

async def render_clusters_list(chat_id:int, edit_message:Optional[Message]=None):
    await ensure_fact_index()
    if not FACT_INDEX.get("cluster"):
        kb=InlineKeyboardMarkup(inline_keyboard=[[InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥", callback_data="back:menu")]])
        text="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /analyze."
        if edit_message:
            try: await edit_message.edit_text(text)
            except Exception: pass
        else:
            await send_safe_message(chat_id, text)
        return
    kb=[]
    for cname in sorted(FACT_INDEX["cluster"].keys(), key=lambda c: FACT_INDEX["cluster"][c]["deficit_need"], reverse=True):
        kb.append([InlineKeyboardButton(text=cname[:40],callback_data=f"cluster:{cname}")])
    kb.append([InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥", callback_data="back:menu")])
    text=f"{EMOJI_CLUSTER} –ö–ª–∞—Å—Ç–µ—Ä—ã:"
    if edit_message:
        try: await edit_message.edit_text(text, reply_markup=InlineKeyboardMarkup(inline_keyboard=kb))
        except Exception: pass
    else:
        await send_safe_message(chat_id, text, reply_markup=InlineKeyboardMarkup(inline_keyboard=kb))

# ==== Detail renderers for SKU / Warehouse / Cluster ====
def build_sku_detail_text(sku:int)->str:
    if not FACT_INDEX.get("sku"):
        return build_html(["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –∏–Ω–¥–µ–∫—Å—É. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /analyze."])
    entry=FACT_INDEX["sku"].get(sku)
    if not entry:
        return build_html([f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è SKU {sku}."])
    name=entry["name"]; total_qty=entry["total_qty"]; worst=entry["worst_coverage"]
    lines=[f"{EMOJI_BOX} ¬ß¬ßB¬ß¬ß{html.escape(name)}¬ß¬ßEB¬ß¬ß (SKU {sku})",
           f"–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–æ–∫: {total_qty}",
           f"–•—É–¥—à–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ: {int(worst*100):02d}%", SEP_THIN]
    for w in entry.get("warehouses", []):
        cov=w["coverage"]; bar, sev = coverage_bar(cov)
        badge=need_pct_text(w["qty"], w["norm"], w["target"])
        lines.append(f"‚Ä¢ ¬ß¬ßB¬ß¬ß{html.escape(w['name'])}¬ß¬ßEB¬ß¬ß: –û—Å—Ç–∞—Ç–æ–∫ {w['qty']} / –ù–æ—Ä–º–∞ {w['norm']} / –¶–µ–ª—å {w['target']} ‚Üí +{w['need']}")
        lines.append(f"  {bar} {sev} ¬∑ {badge}")
        lines.append("")
    if lines and lines[-1]=="":
        lines.pop()
    return build_html(lines)

def build_warehouse_detail_text(wkey:str,wname:str)->str:
    if not FACT_INDEX.get("sku"):
        return build_html(["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –∏–Ω–¥–µ–∫—Å—É. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /analyze."])
    items=[]
    for sku, entry in FACT_INDEX["sku"].items():
        for w in entry.get("warehouses", []):
            if w["wkey"]==wkey:
                items.append({
                    "sku": sku,
                    "name": entry["name"],
                    "qty": w["qty"], "norm": w["norm"], "target": w["target"],
                    "need": w["need"], "coverage": w["coverage"]
                })
    if not items:
        return build_html([f"{EMOJI_WH} ¬ß¬ßB¬ß¬ß{html.escape(wname)}¬ß¬ßEB¬ß¬ß","–ù–µ—Ç –ø–æ–∑–∏—Ü–∏–π."])
    items.sort(key=lambda x:(x["coverage"], -x["need"]))
    lines=[f"{EMOJI_WH} ¬ß¬ßB¬ß¬ß{html.escape(wname)}¬ß¬ßEB¬ß¬ß", SEP_THIN]
    for it in items[:60]:
        bar, sev = coverage_bar(it["coverage"])
        badge=need_pct_text(it["qty"], it["norm"], it["target"])
        lines.append(f"‚Ä¢ ¬ß¬ßB¬ß¬ß{html.escape(it['name'])}¬ß¬ßEB¬ß¬ß (SKU {it['sku']})")
        lines.append(f"  –û—Å—Ç–∞—Ç–æ–∫ {it['qty']} / –ù–æ—Ä–º–∞ {it['norm']} / –¶–µ–ª—å {it['target']} ‚Üí +{it['need']} ¬∑ {badge}")
        lines.append(f"  {bar} {sev}")
        lines.append("")
    if lines and lines[-1]=="":
        lines.pop()
    return build_html(lines)

# ==== Commands ====
@dp.message(Command("version"))
async def cmd_version(m:Message):
    ensure_admin(m.from_user.id)
    await m.answer(version_info())

@dp.message(Command("help"))
@dp.message(Command("start"))
async def cmd_start(m:Message):
    ensure_admin(m.from_user.id)
    load_known_users()
    await ensure_sku_names(force=True)
    await ensure_fact_index()
    if sw and hasattr(sw, "set_global_crossdock") and DEFAULT_DROPOFF_ID:
        try:
            sw.set_global_crossdock(DEFAULT_DROPOFF_ID, DEFAULT_DRO–ü–ûFF_NAME if 'DEFAULT_D–†–û–ü–ûFF_NAME' in globals() else DEFAULT_DROPOFF_NAME)  # type: ignore
            log.info("Global crossdock set from ENV at start: %s (%s)", DEFAULT_DRO–ü–ûFF_NAME if 'DEFAULT_D–†–û–ü–ûFF_NAME' in globals() else DEFAULT_DROPOFF_NAME, DEFAULT_DROPOFF_ID)  # type: ignore
        except Exception as e:
            log.warning("set_global_crossdock at start failed: %s", e)
    try_mount_external_name_resolver()
    await m.answer(f"{EMOJI_OK} –ë–æ—Ç –∞–∫—Ç–∏–≤–µ–Ω. –í–µ—Ä—Å–∏—è {VERSION}.", reply_markup=main_menu_kb())
    kb=[[InlineKeyboardButton(text="–ê–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",callback_data="menu_autobook")]]
    await send_long(m.chat.id, start_overview(), kb=InlineKeyboardMarkup(inline_keyboard=kb))

@dp.message(Command("cluster_map"))
async def cmd_cluster_map(m:Message):
    ensure_admin(m.from_user.id)
    if CLUSTER_MAP:
        lines=["¬ß¬ßB¬ß¬ß–ö–∞—Ä—Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (ENV)¬ß¬ßEB¬ß¬ß",SEP_THIN]
        for k,v in CLUSTER_MAP.items(): lines.append(f"{k} ‚Üí {v}")
    else:
        lines=["¬ß¬ßB¬ß¬ßENV –Ω–µ –∑–∞–¥–∞–Ω ‚Äî —ç–≤—Ä–∏—Å—Ç–∏–∫–∞¬ß¬ßEB¬ß¬ß","–ù–µ–æ–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å–∫–ª–∞–¥—ã ‚Üí '–ü—Ä–æ—á–∏–µ'"]
    await send_long(m.chat.id, build_html(lines))

@dp.message(Command("health"))
async def cmd_health(m:Message):
    ensure_admin(m.from_user.id)
    warn=[]
    if LAST_API_LATENCY_MS>HEALTH_WARN_LATENCY_MS: warn.append("API –º–µ–¥–ª–µ–Ω–Ω–æ")
    if LAST_ANALYZE_MS>HEALTH_WARN_LATENCY_MS: warn.append("–ê–Ω–∞–ª–∏–∑ –º–µ–¥–ª–µ–Ω–Ω–æ")
    status="OK" if not warn else " | ".join(warn)
    lines=["¬ß¬ßB¬ß¬ßHealth¬ß¬ßEB¬ß¬ß",
           f"API {LAST_API_LATENCY_MS:.0f} –º—Å ¬∑ –ê–Ω–∞–ª–∏–∑ {LAST_ANALYZE_MS:.0f} –º—Å",
           f"Snapshots={len(HISTORY_CACHE)} SKU_index={len(FACT_INDEX.get('sku',{}))} Clusters={len(FACT_INDEX.get('cluster',{}))}",
           f"ChatMode={BOT_STATE.get('chat_mode')} Style={'ON' if BOT_STATE.get('style_enabled') else 'OFF'} ClusterView={BOT_STATE.get('cluster_view_mode')} Autobook={'external' if AUTOBOOK_ENABLED else 'fallback'}",
           f"–°—Ç–∞—Ç—É—Å: {status}"]
    await send_long(m.chat.id, build_html(lines))

@dp.message(Command("chat_mode"))
async def cmd_chat_mode(m:Message):
    ensure_admin(m.from_user.id)
    mode=BOT_STATE.get("chat_mode","fact").upper()
    kb=[[InlineKeyboardButton(text="üîÅ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å",callback_data="chatmode:toggle")]]
    await m.answer(build_html(["¬ß¬ßB¬ß¬ß–†–µ–∂–∏–º —á–∞—Ç–∞¬ß¬ßEB¬ß¬ß",f"–¢–µ–∫—É—â–∏–π: {mode}","/fact /general –∏–ª–∏ –∫–Ω–æ–ø–∫–∞."]), reply_markup=InlineKeyboardMarkup(inline_keyboard=kb))

@dp.callback_query(F.data=="chatmode:toggle")
async def cb_chatmode_toggle(c:CallbackQuery):
    cur=BOT_STATE.get("chat_mode","fact")
    BOT_STATE["chat_mode"]="general" if cur=="fact" else "fact"
    save_state()
    await c.message.edit_text(build_html(["¬ß¬ßB¬ß¬ß–†–µ–∂–∏–º —á–∞—Ç–∞¬ß¬ßEB¬ß¬ß",f"–¢–µ–∫—É—â–∏–π: {BOT_STATE['chat_mode'].upper()}","/fact /general –∏–ª–∏ —Å–Ω–æ–≤–∞ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É."]),
                              reply_markup=InlineKeyboardMarkup(inline_keyboard=[[InlineKeyboardButton(text="üîÅ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å",callback_data="chatmode:toggle")]]))
    await c.answer("–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ.")

@dp.message(Command("fact"))
async def cmd_fact(m:Message):
    ensure_admin(m.from_user.id); BOT_STATE["chat_mode"]="fact"; save_state(); await m.answer("FACT")

@dp.message(Command("general"))
async def cmd_general(m:Message):
    ensure_admin(m.from_user.id); BOT_STATE["chat_mode"]="general"; save_state(); await m.answer("GENERAL")

@dp.message(Command("chat"))
async def cmd_chat(m:Message):
    ensure_admin(m.from_user.id); q=m.text.partition(" ")[2].strip()
    if not q: await m.answer("–§–æ—Ä–º–∞—Ç: /chat <—Å–æ–æ–±—â–µ–Ω–∏–µ>"); return
    await m.answer(f"{EMOJI_CHAT} –û–±—â–∞—é—Å—å‚Ä¶")
    raw,mode=await llm_general_answer(m.chat.id,q); styled=style_ai_answer(q,raw,mode,False)
    await send_long(m.chat.id, styled)

@dp.message(Command("analyze"))
async def cmd_analyze(m:Message):
    ensure_admin(m.from_user.id)
    await handle_analyze(m.chat.id)

@dp.message(Command("force_notify"))
async def cmd_force_notify(m:Message):
    ensure_admin(m.from_user.id)
    await m.answer("–û—Ç—á—ë—Ç‚Ä¶")
    await daily_notify_job()
    await m.answer("–ì–æ—Ç–æ–≤–æ.")

@dp.message(Command("diag"))
async def cmd_diag(m:Message):
    ensure_admin(m.from_user.id)
    await ensure_fact_index()
    rep=build_diag_report()
    await send_long(m.chat.id, rep)

@dp.message(Command("stock"))
async def cmd_stock(m:Message):
    ensure_admin(m.from_user.id)
    await render_stock_list(m.chat.id)

@dp.message(Command("warehouses"))
async def cmd_warehouses(m:Message):
    ensure_admin(m.from_user.id)
    await render_warehouses_list(m.chat.id)

@dp.message(Command("clusters"))
async def cmd_clusters(m:Message):
    ensure_admin(m.from_user.id)
    await render_clusters_list(m.chat.id)

@dp.message(Command("ai"))
async def cmd_ai(m:Message):
    ensure_admin(m.from_user.id)
    q=m.text.partition(" ")[2].strip() or "–ü–æ–∫–∞–∂–∏ –∫–∞—Ä—Ç–∏–Ω—É –ø–æ –¥–µ—Ñ–∏—Ü–∏—Ç—É"
    await ensure_fact_index()
    await m.answer(f"{EMOJI_AI} –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é‚Ä¶")
    raw,mode=await llm_fact_answer(q)
    styled=style_ai_answer(q,raw,mode,True)
    await send_long(m.chat.id, styled)

@dp.message(Command("ask"))
async def cmd_ask(m:Message):
    ensure_admin(m.from_user.id)
    q=m.text.partition(" ")[2].strip()
    if not q: await m.answer("–§–æ—Ä–º–∞—Ç: /ask <–≤–æ–ø—Ä–æ—Å>"); return
    await ensure_fact_index()
    await m.answer(f"{EMOJI_AI} –ê–Ω–∞–ª–∏–∑ —Ñ–∞–∫—Ç–æ–≤‚Ä¶")
    raw,mode=await llm_fact_answer(q); styled=style_ai_answer(q,raw,mode,True)
    await send_long(m.chat.id, styled)

@dp.message(Command("ask_raw"))
async def cmd_ask_raw(m:Message):
    ensure_admin(m.from_user.id)
    await ensure_fact_index()
    dump=json.dumps(FACT_INDEX, ensure_ascii=False)
    if len(dump)>3900: dump=dump[:3900]+"...(—É—Å–µ—á–µ–Ω–æ)"
    await send_long(m.chat.id, build_html(["FACT_INDEX (—É—Å–µ—á–µ–Ω–æ):", dump]))

@dp.message(Command("ai_scope"))
async def cmd_ai_scope(m:Message):
    ensure_admin(m.from_user.id)
    tok=_GIGACHAT_TOKEN_MEM; ttl=int(tok["expires_epoch"]-time.time()) if tok and tok.get("expires_epoch") else -1
    insecure=_gigachat_verify_param() is False
    lines=["¬ß¬ßB¬ß¬ßGigaChat —Å—Ç–∞—Ç—É—Å¬ß¬ßEB¬ß¬ß",
           f"Enabled={GIGACHAT_ENABLED} ChatMode={BOT_STATE.get('chat_mode')}",
           f"CID_len={len(GIGACHAT_CLIENT_ID)} SEC_len={len(GIGACHAT_CLIENT_SECRET)} Scope={GIGACHAT_SCOPE}",
           f"Token={'yes' if tok else 'no'} TTL={ttl if ttl>=0 else '-'}",
           f"SSL_mode={os.getenv('GIGACHAT_SSL_MODE','auto')}{' (INSECURE)' if insecure else ''}",
           f"Index SKU={len(FACT_INDEX.get('sku',{}))} Clusters={len(FACT_INDEX.get('cluster',{}))}",
           f"Answer cache={len(ANSWER_CACHE)}"]
    await send_long(m.chat.id, build_html(lines))

@dp.message(Command("ai_reset_token"))
async def cmd_ai_reset_token(m:Message):
    ensure_admin(m.from_user.id)
    global _GIGACHAT_TOKEN_MEM
    _GIGACHAT_TOKEN_MEM={}
    if GIGACHAT_TOKEN_CACHE_FILE.exists():
        try: GIGACHAT_TOKEN_CACHE_FILE.unlink()
        except Exception: pass
    await m.answer("–¢–æ–∫–µ–Ω —Å–±—Ä–æ—à–µ–Ω.")

# ==== Text buttons ====
@dp.message(F.text == "üîç –ê–Ω–∞–ª–∏–∑")
@dp.message(F.text.regexp(r"(?i)^–∞–Ω–∞–ª–∏–∑$"))
async def btn_analyze(m:Message):
    ensure_admin(m.from_user.id)
    await handle_analyze(m.chat.id)

@dp.message(F.text == "üì¶ –¢–æ–≤–∞—Ä—ã")
@dp.message(F.text.regexp(r"(?i)^—Ç–æ–≤–∞—Ä"))
async def btn_stock(m:Message):
    ensure_admin(m.from_user.id)
    await render_stock_list(m.chat.id)

@dp.message(F.text == "üè¨ –°–∫–ª–∞–¥—ã")
@dp.message(F.text.regexp(r"(?i)^—Å–∫–ª–∞–¥"))
async def btn_warehouses(m:Message):
    ensure_admin(m.from_user.id)
    await render_warehouses_list(m.chat.id)

@dp.message(F.text == "üó∫ –ö–ª–∞—Å—Ç–µ—Ä—ã")
@dp.message(F.text.regexp(r"(?i)^–∫–ª–∞—Å—Ç–µ—Ä"))
async def btn_clusters_btn(m:Message):
    ensure_admin(m.from_user.id)
    await render_clusters_list(m.chat.id)

@dp.message(F.text == "üîß –ê–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ")
@dp.message(F.text.regexp(r"(?i)–∞–≤—Ç–æ–±—Ä–æ–Ω"))
async def btn_autobook(m:Message,state:FSMContext):
    ensure_admin(m.from_user.id)
    await state.set_state(AutobookStates.choose_crossdock)
    await m.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Å–∫–ª–∞–¥ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–∫—Ä–æ—Å—Å–¥–æ–∫):", reply_markup=crossdock_kb())

@dp.message(F.text == "ü§ñ AI —á–∞—Ç")
@dp.message(F.text.regexp(r"(?i)^ai\s*—á–∞—Ç"))
async def btn_ai_chat(m:Message,state:FSMContext):
    ensure_admin(m.from_user.id)
    await ensure_fact_index()
    await state.set_state(AIChatState.waiting)
    mode=BOT_STATE.get("chat_mode","fact")
    await m.answer(f"AI —á–∞—Ç –≤–∫–ª—é—á—ë–Ω. –†–µ–∂–∏–º: {mode.upper()}.\n–ù–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å.\n–ö–æ–º–∞–Ω–¥—ã: /fact /general /cancel", reply_markup=main_menu_kb())

@dp.message(F.text == "‚ùå –û—Ç–º–µ–Ω–∞")
@dp.message(F.text.regexp(r"(?i)^–æ—Ç–º–µ–Ω–∞$"))
async def btn_cancel(m:Message,state:FSMContext):
    ensure_admin(m.from_user.id)
    await state.clear()
    await m.answer("–°–æ—Å—Ç–æ—è–Ω–∏—è —Å–±—Ä–æ—à–µ–Ω—ã.", reply_markup=main_menu_kb())

# ==== AI Chat FSM ====
@dp.message(AIChatState.waiting)
async def ai_chat_waiting(m:Message,state:FSMContext):
    ensure_admin(m.from_user.id)
    q=(m.text or "").strip()
    if not q:
        await m.answer("–ü—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç."); return
    lower=q.lower()
    if lower in ("/cancel","cancel","‚ùå –æ—Ç–º–µ–Ω–∞","–æ—Ç–º–µ–Ω–∞"):
        await state.clear(); await m.answer("AI —á–∞—Ç –∑–∞–∫—Ä—ã—Ç.", reply_markup=main_menu_kb()); return
    if lower=="/fact":
        BOT_STATE["chat_mode"]="fact"; save_state(); await m.answer("FACT —Ä–µ–∂–∏–º."); return
    if lower=="/general":
        BOT_STATE["chat_mode"]="general"; save_state(); await m.answer("GENERAL —Ä–µ–∂–∏–º."); return
    mode=BOT_STATE.get("chat_mode","fact")
    try:
        if mode=="fact":
            await ensure_fact_index()
            raw,ai_mode=await llm_fact_answer(q)
            styled=style_ai_answer(q,raw,ai_mode,True)
        else:
            raw,ai_mode=await llm_general_answer(m.chat.id,q)
            styled=style_ai_answer(q,raw,ai_mode,False)
        await send_long(m.chat.id, styled)
    except Exception as e:
        log.exception("ai_chat error")
        await m.answer(f"–û—à–∏–±–∫–∞ AI: {e}")

# ==== Active tasks list (extended) ====
async def render_creating_tasks_list(chat_id:int, edit_message:Message=None):
    """
    –†–µ–Ω–¥–µ—Ä–∏—Ç –ê–ö–¢–ò–í–ù–´–ï –∑–∞–¥–∞—á–∏: –ø—Ä–µ–¥-–∑–∞—è–≤–æ—á–Ω—ã–µ —Å—Ç–∞–¥–∏–∏ (DRAFT/WAIT/SLOT/...), –∏—Å–∫–ª—é—á–∞—è –æ—à–∏–±–∫–∏/–æ—Ç–º–µ–Ω—ã
    –∏ –∏—Å–∫–ª—é—á–∞—è —Å—Ç–∞–¥–∏–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è/—Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–æ–∫.
    """
    try:
        _load_crossdocks_warehouses_env()
        _load_crossdocks_env()
    except Exception:
        pass
    await ensure_sku_names(force=True)
    tasks=await fetch_tasks_global()
    # –£–≤–µ–¥–æ–º–∏–º –æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –ø–æ–ø–∞–ª–∏—Å—å)
    await scan_and_notify_created(chat_id, tasks)
    active=[t for t in tasks if is_active_task(t)]
    TASKS_CACHE[chat_id]=active
    text=build_tasks_list_text(active, chat_id)
    kb=build_tasks_kb(len(active))
    if edit_message:
        try:
            await edit_message.edit_text(text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
            return
        except Exception:
            pass
    await send_safe_message(chat_id, text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)

# Backward-compatible alias (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –∫–æ–¥–∞ –≤—ã–∑—ã–≤–∞–ª–∏ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ –∏–º—è)
async def render_active_tasks_list(chat_id:int, edit_message:Optional[Message]=None):
    await render_creating_tasks_list(chat_id, edit_message)

# ==== Applications (–ó–∞—è–≤–∫–∏) ====
def build_applications_list_text(apps:List[Dict[str,Any]], chat_id:int)->str:
    if not apps:
        return build_html(["¬ß¬ßB¬ß¬ßüìÑ –ó–∞—è–≤–∫–∏ (0)¬ß¬ßEB¬ß¬ß", SEP_THIN, "–ó–∞—è–≤–æ–∫ –Ω–µ—Ç."])
    lines=[f"¬ß¬ßB¬ß¬ßüìÑ –ó–∞—è–≤–∫–∏ ({len(apps)})¬ß¬ßEB¬ß¬ß", SEP_THIN]
    for i,t in enumerate(apps,1):
        em,stage=classify_task_stage(t)
        qty=_sum_qty(t)
        date=t.get("date") or (t.get("desired_from_iso","")[:10] if t.get("desired_from_iso") else "-")
        slot=_human_window(t.get("timeslot") or "", t.get("desired_from_iso") or "", t.get("desired_to_iso") or "")
        tid=t.get("id") or "-"
        wh=_task_warehouse_name(t)
        cd=_resolve_crossdock_name_warehouses(t, chat_id)
        status_label=_application_status_text((t.get("status") or t.get("state") or ""))
        lines.append(f"{i}) {em} {stage} | ¬ß¬ßB¬ß¬ß{qty} —à—Ç¬ß¬ßEB¬ß¬ß | {date} ‚Äî {slot} | ¬ß¬ßB¬ß¬ß{tid}¬ß¬ßEB¬ß¬ß")
        lines.append(f"   –°—Ç–∞—Ç—É—Å: {status_label}")
        lines.append(f"   –°–∫–ª–∞–¥ –ø–æ—Å—Ç–∞–≤–∫–∏: ¬ß¬ßB¬ß¬ß{html.escape(wh)}¬ß¬ßEB¬ß¬ß | –ö—Ä–æ—Å—Å–¥–æ–∫: ¬ß¬ßB¬ß¬ß{html.escape(cd)}¬ß¬ßEB¬ß¬ß")
        sl=t.get("sku_list")
        if isinstance(sl,list) and sl:
            lines.append("   –ü–æ–∑–∏—Ü–∏–∏:")
            for it in sl[:20]:
                sku=it.get("sku"); q=it.get("total_qty") or it.get("qty") or 0
                sname=get_sku_name_local(int(sku)) if sku else "-"
                lines.append(f"   ‚Ä¢ ¬ß¬ßB¬ß¬ß{html.escape(sname)}¬ß¬ßEB¬ß¬ß (SKU {sku}) ‚Äî {q} —à—Ç")
        lines.append("")
    if lines and lines[-1]=="":
        lines.pop()
    lines.append(SEP_THIN)
    return build_html(lines)

async def render_applications_list(chat_id:int, edit_message:Optional[Message]=None):
    try:
        _load_crossdocks_warehouses_env()
        _load_crossdocks_env()
    except Exception:
        pass
    await ensure_sku_names(force=True)
    tasks=await fetch_tasks_global()
    # –£–≤–µ–¥–æ–º–∏–º –æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö
    await scan_and_notify_created(chat_id, tasks)
    apps=[t for t in tasks if is_application_task(t)]
    APPS_CACHE[chat_id]=apps
    # –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø–æ —Å–æ–±—ã—Ç–∏—è–º
    if not apps:
        text=build_supplies_last_created(limit=5)
        kb=InlineKeyboardMarkup(inline_keyboard=[
            [InlineKeyboardButton(text=f"{EMOJI_REFRESH} –û–±–Ω–æ–≤–∏—Ç—å",callback_data="apps:refresh")],
            [InlineKeyboardButton(text="‚¨Ö –ú–µ–Ω—é",callback_data="back:menu")],
            [InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å",callback_data="apps:close")]
        ])
    else:
        text=build_applications_list_text(apps, chat_id)
        kb=build_apps_kb(len(apps))
    if edit_message:
        try:
            await edit_message.edit_text(text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
            return
        except Exception:
            pass
    await send_safe_message(chat_id, text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)

# ==== Buttons and commands for tasks/apps ====
@dp.message(F.text == "üìã –ó–∞–¥–∞—á–∏")
async def btn_tasks(m:Message):
    ensure_admin(m.from_user.id)
    await render_creating_tasks_list(m.chat.id)

@dp.message(Command("tasks"))
async def cmd_tasks(m:Message):
    ensure_admin(m.from_user.id)
    await render_creating_tasks_list(m.chat.id)

@dp.message(Command("all_tasks"))
async def cmd_all_tasks(m:Message):
    ensure_admin(m.from_user.id)
    await render_creating_tasks_list(m.chat.id)

@dp.callback_query(F.data=="tasks:refresh")
async def cb_tasks_refresh(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    await render_creating_tasks_list(c.message.chat.id, edit_message=c.message)
    await c.answer("–û–±–Ω–æ–≤–ª–µ–Ω–æ")

@dp.callback_query(F.data=="tasks:close")
async def cb_tasks_close(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    try:
        await c.message.edit_reply_markup(reply_markup=None)
        await c.message.edit_text(build_html(["–°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∑–∞–∫—Ä—ã—Ç."]))
    except Exception:
        pass
    await c.answer()

@dp.callback_query(F.data.startswith("tasks:detail:"))
async def cb_tasks_detail(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    try: idx=int(c.data.rsplit(":",1)[1])-1
    except Exception: await c.answer(); return
    tasks=TASKS_CACHE.get(c.message.chat.id) or []
    if idx<0 or idx>=len(tasks):
        await c.answer("–ù–µ—Ç –∑–∞–¥–∞—á–∏.")
        await render_creating_tasks_list(c.message.chat.id, edit_message=c.message)
        return
    t=tasks[idx]
    tid=str(t.get("id") or "-")
    text=build_task_detail_text(t, c.message.chat.id)
    kb=task_detail_kb(tid)
    try:
        await c.message.edit_text(text,parse_mode="HTML",reply_markup=kb,disable_web_page_preview=True)
    except Exception:
        await send_safe_message(c.message.chat.id,text,parse_mode="HTML",reply_markup=kb,disable_web_page_preview=True)
    await c.answer()

@dp.callback_query(F.data.startswith("tasks:delete_id:"))
async def cb_tasks_delete_id(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    tid=c.data.split(":",2)[2]
    ok=False
    try:
        ok = await delete_task_by_id(tid)
    except Exception as e:
        log.warning("delete by id failed: %s", e)
    _remove_task_from_caches(c.message.chat.id, tid)
    await c.answer("–£–¥–∞–ª–µ–Ω–æ." if ok else "–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å (—Å–º. –ª–æ–≥–∏).")
    await render_creating_tasks_list(c.message.chat.id, edit_message=c.message)

@dp.callback_query(F.data=="tasks:delete_all")
async def cb_tasks_delete_all(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    cnt = await delete_all_tasks_for_chat(c.message.chat.id)
    await c.answer(f"–£–¥–∞–ª–µ–Ω–æ –∑–∞–¥–∞—á: {cnt}")
    await render_creating_tasks_list(c.message.chat.id, edit_message=c.message)

@dp.message(F.text == "üìÑ –ó–∞—è–≤–∫–∏")
async def btn_zayavki(m:Message):
    ensure_admin(m.from_user.id)
    await render_applications_list(m.chat.id)

@dp.message(Command("supplies"))
async def cmd_supplies(m:Message):
    ensure_admin(m.from_user.id)
    await render_applications_list(m.chat.id)

@dp.callback_query(F.data=="apps:refresh")
async def cb_apps_refresh(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    await render_applications_list(c.message.chat.id, edit_message=c.message)
    await c.answer("–û–±–Ω–æ–≤–ª–µ–Ω–æ")

@dp.callback_query(F.data=="apps:close")
async def cb_apps_close(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    try:
        await c.message.edit_reply_markup(reply_markup=None)
        await c.message.edit_text(build_html(["–°–ø–∏—Å–æ–∫ –∑–∞—è–≤–æ–∫ –∑–∞–∫—Ä—ã—Ç."]))
    except Exception:
        pass
    await c.answer()

@dp.callback_query(F.data.startswith("apps:detail:"))
async def cb_apps_detail(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    try: idx=int(c.data.rsplit(":",1)[1])-1
    except Exception: await c.answer(); return
    apps=APPS_CACHE.get(c.message.chat.id) or []
    if idx<0 or idx>=len(apps):
        await c.answer("–ù–µ—Ç –∑–∞—è–≤–∫–∏.")
        await render_applications_list(c.message.chat.id, edit_message=c.message)
        return
    t=apps[idx]
    text=build_task_detail_text(t, c.message.chat.id)
    kb=apps_detail_kb()
    try:
        await c.message.edit_text(text,parse_mode="HTML",reply_markup=kb,disable_web_page_preview=True)
    except Exception:
        await send_safe_message(c.message.chat.id,text,parse_mode="HTML",reply_markup=kb,disable_web_page_preview=True)
    await c.answer()

# ==== Stock/Warehouses/Clusters callbacks ====
@dp.callback_query(F.data=="open:stock")
async def cb_open_stock(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    await render_stock_list(c.message.chat.id, edit_message=c.message)
    await c.answer()

@dp.callback_query(F.data=="open:warehouses")
async def cb_open_wh(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    await render_warehouses_list(c.message.chat.id, edit_message=c.message)
    await c.answer()

@dp.callback_query(F.data=="open:clusters")
async def cb_open_clusters(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    await render_clusters_list(c.message.chat.id, edit_message=c.message)
    await c.answer()

@dp.callback_query(F.data.startswith("sku:"))
async def cb_sku_detail(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    try:
        sku=int(c.data.split(":",1)[1])
    except Exception:
        await c.answer("–ù–µ–≤–µ—Ä–Ω—ã–π SKU")
        return
    await ensure_fact_index()
    text=build_sku_detail_text(sku)
    kb=InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥ –∫ —Ç–æ–≤–∞—Ä–∞–º", callback_data="open:stock")],
        [InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å", callback_data="noop")]
    ])
    try:
        await c.message.edit_text(text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    except Exception:
        await send_safe_message(c.message.chat.id, text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    await c.answer()

@dp.callback_query(F.data.startswith("whid:"))
async def cb_wh_detail(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    hid=c.data.split(":",1)[1]
    pair=WAREHOUSE_CB_MAP.get(hid)
    if not pair:
        await c.answer("–°–∫–ª–∞–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –æ–±–Ω–æ–≤–ª—è—é —Å–ø–∏—Å–æ–∫‚Ä¶")
        await render_warehouses_list(c.message.chat.id, edit_message=c.message)
        return
    wkey,wname=pair
    await ensure_fact_index()
    text=build_warehouse_detail_text(wkey,wname)
    kb=InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥ –∫ —Å–∫–ª–∞–¥–∞–º", callback_data="open:warehouses")],
        [InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å", callback_data="noop")]
    ])
    try:
        await c.message.edit_text(text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    except Exception:
        await send_safe_message(c.message.chat.id, text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    await c.answer()

@dp.callback_query(F.data.startswith("cluster:"))
async def cb_cluster_detail(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    cname=c.data.split(":",1)[1]
    await ensure_fact_index()
    text=build_cluster_detail(cname, FACT_INDEX.get("cluster",{}), FACT_INDEX.get("sku",{}), short=False)
    kb=InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚¨Ö –ù–∞–∑–∞–¥ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∞–º", callback_data="open:clusters")],
        [InlineKeyboardButton(text="‚úñ –ó–∞–∫—Ä—ã—Ç—å", callback_data="noop")]
    ])
    try:
        await c.message.edit_text(text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    except Exception:
        await send_safe_message(c.message.chat.id, text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    await c.answer()

@dp.callback_query(F.data=="back:menu")
async def cb_back_menu(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    await c.message.edit_text("–í—ã –≤ –≥–ª–∞–≤–Ω–æ–º –º–µ–Ω—é.", reply_markup=None)
    await bot.send_message(c.message.chat.id, "–ì–æ—Ç–æ–≤–æ.", reply_markup=main_menu_kb())
    await c.answer()

# ==== Analyze filters and actions ====
def _build_filtered_deficit_text(flat:List[Dict[str,Any]], mode:str)->str:
    # mode: all | crit | mid
    if not flat:
        return build_html([f"{EMOJI_ANALYZE} –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."])
    def pass_item(it):
        cov=it.get("coverage", 0.0)
        if mode=="crit":
            return cov<0.5
        if mode=="mid":
            return 0.5<=cov<0.8
        return True
    by_sku: Dict[int, List[Dict[str,Any]]] = {}
    for it in flat:
        if pass_item(it):
            by_sku.setdefault(int(it["sku"]), []).append(it)
    if not by_sku:
        return build_html([f"{EMOJI_ANALYZE} –ù–µ—Ç –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞."])
    lines=[f"{EMOJI_ANALYZE} ¬ß¬ßB¬ß¬ß–î–µ—Ñ–∏—Ü–∏—Ç ({'–≤—Å–µ' if mode=='all' else ('–∫—Ä–∏—Ç–∏—á–Ω–æ' if mode=='crit' else '50‚Äì80%')})¬ß¬ßEB¬ß¬ß", LEGEND_TEXT, SEP_THIN]
    order=sorted(by_sku.keys(), key=lambda s: min(x["coverage"] for x in by_sku[s]))
    for sku in order[:80]:
        items=sorted(by_sku[sku], key=lambda x:x["coverage"])
        name=items[0].get("name") or SKU_NAME_CACHE.get(sku, f"SKU {sku}")
        lines.append(f"‚Ä¢ <b>{html.escape(name)}</b> (SKU {sku})")
        for it in items[:6]:
            bar, sev = coverage_bar(it["coverage"])
            badge=need_pct_text(it["qty"], it["norm"], it["target"])
            lines.append(f"  {html.escape(it['warehouse_name'])}: +{it['need']} ¬∑ {badge}")
            lines.append(f"  {bar} {sev}")
        lines.append(SEP_THIN)
    return "\n".join(lines)

@dp.callback_query(F.data.startswith("filter:"))
async def cb_filter(c:CallbackQuery):
    """
    Filter handler for Analysis view. Uses cache or triggers recomputation if missing.
    """
    ensure_admin(c.from_user.id)
    mode=c.data.split(":",1)[1]
    # Ensure cache exists, recompute if necessary
    cache = await _ensure_deficit_cache_for_chat(c.message.chat.id)
    flat = cache.get("flat") or []
    text=_build_filtered_deficit_text(flat, mode)
    kb=InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–í—Å–µ",callback_data="filter:all"),
         InlineKeyboardButton(text="–ö—Ä–∏—Ç–∏—á–Ω–æ",callback_data="filter:crit"),
         InlineKeyboardButton(text="50‚Äì80%",callback_data="filter:mid")],
        [InlineKeyboardButton(text=f"{EMOJI_REFRESH} –û–±–Ω–æ–≤–∏—Ç—å",callback_data="action:reanalyze")],
        [InlineKeyboardButton(text="–ê–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",callback_data="menu_autobook")],
    ])
    try:
        await c.message.edit_text(text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    except Exception:
        await send_safe_message(c.message.chat.id, text, parse_mode="HTML", reply_markup=kb, disable_web_page_preview=True)
    await c.answer("–§–∏–ª—å—Ç—Ä –ø—Ä–∏–º–µ–Ω—ë–Ω")

@dp.callback_query(F.data=="action:reanalyze")
async def cb_reanalyze(c:CallbackQuery):
    ensure_admin(c.from_user.id)
    await c.answer("–ü–µ—Ä–µ—Å—á—ë—Ç‚Ä¶")
    await handle_analyze(c.message.chat.id, verbose=False)

@dp.callback_query(F.data=="noop")
async def cb_noop(c:CallbackQuery):
    # –ü—Ä–æ—Å—Ç–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–ø–ª—ã–≤–∞—é—â–µ–µ
    await c.answer()

# ==== Scheduler and startup ====
scheduler = AsyncIOScheduler(timezone=ZoneInfo(TZ_NAME))

def setup_scheduler():
    try:
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Å–Ω–∏–º–æ–∫
        scheduler.add_job(snapshot_job, "interval", minutes=SNAPSHOT_INTERVAL_MINUTES, id="snapshot_job", replace_existing=True)
    except Exception as e:
        log.warning("Scheduler: snapshot_job add failed: %s", e)
    try:
        # –ï–∂–µ–¥–Ω–µ–≤–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
        scheduler.add_job(daily_notify_job, "cron", hour=DAILY_NOTIFY_HOUR, minute=DAILY_NOTIFY_MINUTE, id="daily_notify", replace_existing=True)
    except Exception as e:
        log.warning("Scheduler: daily_notify add failed: %s", e)
    try:
        # –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
        scheduler.add_job(maintenance_job, "interval", minutes=HISTORY_PRUNE_EVERY_MINUTES, id="maintenance", replace_existing=True)
    except Exception as e:
        log.warning("Scheduler: maintenance add failed: %s", e)
    try:
        scheduler.start()
    except Exception as e:
        log.warning("Scheduler start failed: %s", e)

async def on_startup():
    load_state()
    load_cache()
    load_known_users()
    try:
        await init_snapshot()
    except Exception as e:
        log.warning("init_snapshot failed: %s", e)
    setup_scheduler()
    # –†–æ—É—Ç–µ—Ä –≤–Ω–µ—à–Ω–µ–≥–æ –∞–≤—Ç–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if AUTOBOOK_ENABLED and autobook_router is not None:
        try:
            dp.include_router(autobook_router)
            log.info("External autobook router included.")
        except Exception as e:
            log.warning("include external router failed: %s", e)
    # Supply-watch background scheduler (–µ—Å–ª–∏ –µ—Å—Ç—å)
    try:
        if register_supply_scheduler:
            sig=inspect.signature(register_supply_scheduler)
            if len(sig.parameters)>=3:
                register_supply_scheduler(bot, dp, scheduler)
            elif len(sig.parameters)==2:
                register_supply_scheduler(bot, dp)
            elif len(sig.parameters)==1:
                register_supply_scheduler(dp)
            else:
                register_supply_scheduler()
            log.info("supply_watch scheduler registered.")
    except Exception as e:
        log.warning("register_supply_scheduler error: %s", e)

    log.info("Bot started. Version %s", VERSION)

def run():
    loop=asyncio.get_event_loop()
    for sig in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig, lambda s=sig: asyncio.create_task(bot.session.close()))
        except Exception:
            pass
    loop.run_until_complete(on_startup())
    try:
        loop.run_until_complete(dp.start_polling(bot))
    except KeyboardInterrupt:
        pass
    finally:
        try:
            loop.run_until_complete(bot.session.close())
        except Exception:
            pass

if __name__ == "__main__":
    run()
